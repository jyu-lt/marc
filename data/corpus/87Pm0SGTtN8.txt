If we didn't have AI, we'd be in a panic
right now about what's going to happen
to the economy. We've actually been in a
regime for 50 years of very slow
technological change in the face of
declining population growth. The timing
has worked out miraculously well. We're
going to have AI and robots precisely
when we actually need them. The
remaining human workers are going to be
at a premium, not at a discount.
>> How big of a deal is the moment in time
that we are living through right now?
>> This is a very, very historic time. AI
is the philosopher stone. Now we have a
technology that transfers the most
common thing in the world which is sand
converted into the most rare thing in
the world which is thought.
>> We spent a lot of time with the most
cutting edge AI forward founders. The
most leading edge founders are thinking
of can you have entire companies where
the founder does everything.
>> There's all this concern that young
people jobs are not going to be there
for them. AI is replacing them.
>> Everybody wants to talk about job loss
but really what you want to look at is
task loss. The job persists longer than
the individual tasks.
>> What's your sense of just the future of
three very specific roles? Product
manager, engineer, designer. There's
like a Mexican standoff happening
between those three roles. Every coder
now believes they can also be a product
manager and a designer because they have
AI. Every product manager thinks they
can be a coder and a designer. And then
every designer knows they can be a
product manager and a coder. They're
actually all kind of correct. What
happens is the additive effect of being
good at two things is more than double.
The additive effect of being good at
three things is more than triple. You
become a super relevant specialist in
the combination of the domains.
>> People aren't fully grasping how much
this changing. And people who really
want to improve themselves and develop
their careers should be spending every
spare hour in my view at this point
talking to AI being like, "All right,
train me up."
Today my guest is Mark Andre, one of the
most seinal figures in tech and in
business. He invented the web browser,
built the world's largest venture firm.
He's also a multi-time founder and an
investor in essentially every
generational tech company and is also
one of the most clear-minded, lateral,
and insightful thinkers about both the
past and the future of technology. In
this very special conversation, we chat
about how unique and significant the
moment that we are all living through
right now is, what skills he's teaching
his kids to thrive in the AI future,
what happens to product managers,
designers, and engineers in the coming
years. where moes exist in AI, what the
most AI native founders are doing
differently, and so much more that is
just scratching the surface of this very
deep and important conversation. You are
going to walk away from this chat being
smarter about what is going on in the
world right now and where things are
heading. A huge thank you to my
newsletter community and focus on X for
suggesting topics and questions for this
conversation. If you enjoy this podcast,
don't forget to subscribe and follow it
in your favorite podcasting app or
YouTube. It helps tremendously. And if
you become an insider subscriber of my
newsletter, you get a year free of over
20 incredible products, including a year
free of lovable, replet, bold, gamma,
nad, linear, superhuman, devon, post
hog, dscript, whisperflow, perplexity,
warp, granola, magic patterns, raycast,
chappd, mob, and stripe atlas. Head on
over to lenny'snewsletter.com and click
product pass. With that, I bring you
Mark Andre after a short word from our
sponsors. Today's episode is brought to
you by DX, the developer intelligence
platform designed by leading
researchers. To thrive in the AI era,
organizations need to adapt quickly. But
many organization leaders struggle to
answer pressing questions like which
tools are working? How are they being
used? What's actually driving value? DX
provides the data and insights that
leaders need to navigate this shift.
With DX, companies like Dropbox,
Booking.com, Adion, and Intercom get a
deep understanding of how AI is
providing value to their developers and
what impact AI is having on engineering
productivity. To learn more, visit DX's
website at getd dx.com/lenny.
That's getdx.com/lenny.
If you're a founder, the hardest part of
starting a company isn't having the
idea. It's scaling the business without
getting buried in back office work.
That's where B comes in. Brex is the
intelligent finance platform for
founders. With Brex, you get high limit
corporate cards, easy banking, high
yield treasury, plus a team of AI agents
that handle manual finance tasks for
you. They'll do all the stuff that you
don't want to do, like file your
expenses, scour transactions for waste,
and run reports, all according to your
rules. With Brexit AI agents, you can
move faster while staying in full
control. One in three startups in the
United States already runs on Brex. You
can too at brex.com.
Mark Andre, thank you so much for being
here and welcome to the podcast.
>> Awesome, Lenny. Thank Thank you. It's
great to be here.
>> I want to start with just a big picture
question. I have a billion directions I
want to go, but I think this is going to
give us a little bit of a frame of
reference. How big of a deal is the
moment in time that we are living
through right now?
>> This is a very very historic time. I
think 2025 was maybe the most
interesting year in my entire career and
and probably life and I think I would
expect 2026 to exceed that.
>> Wow, that says a lot.
>> Yeah, I've se I've seen some stuff. So,
um it feels like two things are
happening. one is the the the trust that
a lot of people have had in kind of what
you describe as kind of legacy
institutions around the world is I I
think in kind of full scale collapse
right now. By the way, there's a lot of
data data to support that. And so I
think there's just there's there's like
a lot of structures and orders and uh
institutions that people have just
relied on for a long time that have just
proven to not be up for the up for the
challenge. And then kind of
corresponding with that is the national
and global conversation have become like
let's say liberated. Um, and so, you
know, this sort of incredible revolution
that we have in in kind of, uh, you
know, what I've described as freedom of
speech, freedom of thought, um, ability
for people to openly discuss things that
maybe they couldn't discuss even a few
years ago, you know, is just
dramatically expanded. And I think
that's that's now on on a one-way train
for just a much broader range of
discourse. And then, you know, there's
also just these like incredibly massive
geopolitical shifts that are happening.
And obviously, the the US is changing a
lot, Europe is changing a lot, China is
changing a lot, Latin America, by the
way, is changing a lot. very dramatic,
you know, events playing out down there
right now, you know, kind of all over
the world. Like I think a lot of
assumptions are being pulled out in the
into the daylight and and re-examined.
And and then it's kind of the fact that
all these things are happening at the
same time, right? And so you've got all
of these countries and industries, you
know, where things are kind of
increasingly upheaval, but you have AI
is this kind of new technology that's
going to really affect things. And then
you've got, you know, people, you know,
citizens being able to fully
participate, uh, and being able to argue
things out. So, it's it's kind of like
those three kind of big mega things are
kind of all colliding um at the same
time. And I I think we're probably just
the very beginning of all three of
those. And those all feel like kind of,
you know, historical, you know, moment
shifts, you know, comparable in
magnitude to maybe the fall of the
Berlin Wall in 1989, you know, maybe
maybe the end of World War II. Um you
know, kind of moments like that. It
certainly feels like that.
>> Good God,
what a time to be alive.
>> Yeah. In terms of the AI piece, which is
where a lot of people are trying to
figure out what to do, what do you think
isn't being priced in yet in terms of
the impact AI is going to have on say
the world or just people listening?
>> The I think at I think at this point I
think it's pretty clear with it with you
know our technology hats on that like
this stuff is really working now right
and so there there was this you know
kind of you know when when there was a
chat GPD moment you know three years ago
it was only by the way only three years
ago right? um was the chat GPD moment
and and the big question was all right
this this is like incredibly fun and
creative and like we have machines now
that can compose Shakespeare and silence
and rap lyrics and like you know this is
amazing but then there was there you
know there's this big question like can
you can you harness this technology for
reasoning um and for you know problem
solving in domains that like really
matter you know medicine and science and
and and law and so forth um and and you
know it turns out the answer to that is
yes right um and you know the the last
12 months and especially the last even
just the last three months have really
proven that like AI can really do like
you know you're seeing it all now you
know you can actually you know AI is now
developing new math theorems um you know
there you know over the holiday break
you know there's sort of the what it
feels like the AI coding thing you know
really hit critical mass uh and the
world's best you the world's best
programmers right including like
Lisbald's you know for for the first
time over the holiday break basically
said yeah AI is now coding better than
we can and so that you know that's
that's incredibly incredibly powerful
and I think we we all you know kind of I
think assume that AI now is going to get
really good at reasoning um in in any
domain do in which there are verifiable
answers and so that that you know that's
going to include like many very
important domains. So um so like for the
technology feels like it's it's it's
moving fast and and it's going to be
working really well. Um I think the
thing that is not well understood I I
think a lot of people have a I think you
know a lot of people in the industry
have kind of what I would describe as
this one-dimensional thing which is okay
as a result of the technology not
working AI just kind of sweeps sweeps
the world and changes everything. And I
think that's that's kind of the wrong
that's kind of the wrong frame. I think
it's based on an incomplete
understanding of of the world that we
live in or the world that we've been
living in for the last you know 80 years
and I would call out two things in
particular. So one is it has I think
it's felt to us like in the US and the
west for the last you know whatever 30
years or 50 years it's felt like we've
been in a time of great technological
change but actually if you look for
actually evidence of that like in stat
in statistical evidence of that
analytical evidence of that like you
basically can't find it. Um and in
particular um economists have a way of
measuring the rate of technological
change in the economy that is
productivity growth which which we could
talk about what that means but basically
it's it's a it's sort of the
mathematical expression of the impact of
technology uh on the economy and
productivity growth for the last 50
years has actually been very low not
very high so we all feel like it's been
very high there's been lots of
technological change what's actually
happening is it's it's been very low and
in fact the pace of productivity growth
like in the US is is running at like a
half of what it in my lifetime, in our
lifetimes, it's been running at about a
half the pace um that it ran in um
between 1940 and 1970. And it's been
running at about a third the pace that
it ran between about 1870 to about 1940.
And so statistically in the US in the
west technology progress in the economy,
technology impact the economy has
actually slowed way down. And so we, you
know, the AI thing is is going to hit,
but it's hitting an environment in which
we, we have actually had almost no
technological progress in the actual
economy for a very long time. So we
could talk about that. And then there's
this other like just incredible thing
that's happening, which is the the, you
know, s the de demographic collapse,
right? It's sort of a western
phenomenon, an increasingly global
phenomenon, which is, you know, the rate
of reproduction of the human species is
is in rapid decline. And you know there
are many countries you know including
the US where you know the rate of
reproduction is you know under two you
know meaning meaning that you know many
many countries around the world by the
way including China which is a really
big deal are actually going to
depopulate over the next century um and
so you have this kind of precondition
that says there's actually been very
little techn technological progress
happening in the world um and the world
is going to depopulate um and so AI is
going to enter the world a world in
which those two things are true and I
think it's inc this is incredibly
important because we actually need AI to
work in order to get productivity growth
up, which is what we need to get
economic growth up. And we actually need
AI to work because we're going to need,
you know, we're going to need machines
to do all the jobs that we're not going
to have people to do because we're we're
literally going to depopulate we're
going to depopulate the planet over the
next hundred years. And so I I think the
interplay of these factors is is going
to be much more interesting and and
frankly more more more complex than a
lot of people have been thinking.
>> I'm going to follow this thread about
kids. I know you have a kid and one of
my most my favorite lenses into how
people think and what they value is what
they're teaching their kids, what
they're steering their kids towards.
>> Are there specific skills or I don't
even careers that you're steering your
kid towards?
>> The way I think about this and you know,
yeah, we we have a 10-year-old and so,
you know, we and we actually homeschool
and so we we we think a lot about this.
Um so I think the way to think about the
impact of AI on on people on
specifically people as individuals I
think it's it's it's actually you know a
lot of people just focus on kind of this
you know this kind of very I would say
straightforward and or overly simplistic
view of just literally job gains you
know job losses which we could talk
about but there's two specific things at
the level of like an individual person
and individual kid so I think it's
pretty clear that AI is going to take
people who are good at doing things and
it's going to make them very good at
doing things right and so It's going to
be a tool that's going to sort of raise
the average kind of across the board.
And you know, look, you see that playing
out already. You know, anybody who's in
a position where they need to, you know,
write something or design something or
write code or whatever, if they're if
they're pretty good at it today, they
use they use AI and all of a sudden
they're very good at it. And so there
there's sort of that aspect to it. And I
think the the the way the education
system very large is going to teach is
going to kind of teach AI is is going to
be based, you know, hopefully a lot on
that. But then there's this other thing
that's happening which we're also
starting to see and we're really seeing
it particularly in coding right now. Um
where the really great people are
becoming like spectacularly great,
right? Um and so you just you kind of
use it use the term you think about like
the supermpowered individual, right? So
the individual who is like really good
um at coding or really good at making
movies or really good at making songs or
really good at designing you know making
art or whatever whatever those things
are or or you know or podcasting or you
know hopefully venture capital you know
if if you're very good at it and you can
really harness AI you can become
spectacularly great uh and like super
productive right and you know I'm sure
you have a lot of friends in this in
this category as well but like you know
the the really really good coders are
experiencing this right you know, my
friends who are really good coders are
like, "Oh my god, all of a sudden I'm
not twice as good as I used to be. I'm
like 10 times as good as I used to be."
And so I think at the at the unit of
like n equals one of like an individual
kid, I think the question is kind of how
do you get them in a position where
they're kind of this kind of
supermpowered individual such that
they're going to be really kind of deep
in whatever it is they're going to do,
but they're going to they're going to be
deep in a way that's going to let them
fully use the power of AI to be not just
great, but to be like spectacularly
great. Um, and and I think that that
that's that's going to be the real, you
know, that that that that that's the
real opportunity and that, you know, at
least that's what we're shooting for and
that's what I would encourage parents to
shoot for.
>> So, what I heard there is essentially
agency, this word that we see on Twitter
all the time is building uh agency, them
not waiting for someone to tell them
what to do, figuring out what to do.
>> Yeah. Yeah. So, this this this thing
with this this term agency that's become
very very um you know, very popular um
certainly California for the last couple
years. It's really interesting because
it's it's I had a lot of trouble with
this early on because I'm like agency.
What are they talking about? And what
what they're kind of talking about is
like, you know, initiative,
you know, um you know, willingness to,
you know, you could just do things. Um
you know, uh what is it? Uh the the demo
bird has the great term live player. Um
you know, you you you can be like a
primary participant in events. And at
first I was like, well, yeah, like
that's kind of obvious, right? like of
course and and then I'm like oh actually
it's not so obvious anymore because kind
of your your point I think so much of
our society is based on like there are
all these rules and everybody gets
taught kind of by default you're
supposed to follow all these rules right
and then everybody if you like break the
rules like everybody gets freaked out
it's like oh my god he broke the rules
and so like we we we have somehow worked
our our way our way kind of you know I
don't know psychologically
sociologically you know kind of into a
state in which I guess the natural
assumption for a lot of people is you
know the thing that you for example you
want to train kids to do is like follow
all the rules. Um, and you know, you
could argue that kind of you know, for
example, the you know, the school
system, the K through2 school system or
whatever has gotten kind of more and
more focused on that over time. And it's
like yeah, it's like no, you you should
actually and again, especially at unit
unit n equals one, like of your kid.
It's like and look, there's there's
something to be had. We I just had this
conversation my 10-year-old last night
actually. I I I rolled out uh uh the
concept of uh you know, in order to
lead, you must first learn to obey,
right? In order to you know, issue
orders, you must learn how to follow
orders. and you know you kind of try to
keep keep him with some level of
structure in his life and not just and
not just pure agency but yeah I mean and
so look you know some rules are
important and so forth but yeah no look
there there is like a huge b there's
just a huge premium in life on being
somebody who is able to like fully take
responsibility for things fully take
charge run an organization lead a
project create something new um and you
know maybe yeah that that has been maybe
a little bit diminished in our culture
over the last 30 years it you know it's
it's healthy you know that that you know
that that there's now a term for that
that that is coming back back into vogue
and then and then and again that's how I
view AI for kids is like okay AI should
be the ultimate letter on the world for
a kid with agency to be able to say okay
I can actually be a primary contributor
right whether that's I can be a primary
contributor in everything from you know
developing new areas of physics to
writing code to being an artist uh you
know to writing you know to writing
novels like you know whatever that thing
is I I can fully participate in the
world I can really change things and I
and I that that feel that The
combination of that idea combined with
this technology feels very healthy to
me.
>> What is that quote about? Give me a
lever and I'll move the world.
>> And I'll move the world. Yeah, that's
exactly right. Well, so it's actually
funny you mentioned that. So the the um
the uh the the early kind of scientists
including like Isaac Newton were super
obsessed with with you know this concept
of alchemy, right? It's like you know
they you know they you know they
developed like you know Newton he's like
developed Newtonian physics and he
developed like calculus and all these
things but the thing he was really
obsessed with was alchemy which was the
thing he could never get to work right
and and and alchemy was the
transmutation of lead into gold which
meant the transmutation of something
that was very common which was lead into
something that was very rare and
valuable which was gold. And you know
they there was this the he spent you
know decades trying to figure out this
thing called the philosopher stone which
would be basically the the machine or
the process that would would be able to
transmute the rare you know the common
thing into the rare thing led into gold
and he never figured it out and you know
it's incredibly frustrating nobody ever
figured that out and now we literally
with AI have a technology that transfers
sand into thought
>> just blew my mind
>> right the the most common thing in the
world which is sand converted into the
most rare thing in the world which is
Right. And and so AI is it is it is the
it is the philosopher stone. Like it it
is that it it actually is that and it's
just this incredibly powerful tool. Um
and and that's where I that's where I
get so excited. I mean and again this is
what we're doing with our 10-year-old
which is like all right a primary thing
that we want to make sure to to do is to
make sure that he knows fully how to
leverage and and get and get benefit out
of the philosopher stone, right? Which
is uh you know which is to say AI and
that that and then you know that's
certainly central to everything we're
teaching him. you know, there's there's
this meme going around that um you know,
Silicon Valley people don't let their
kids use computers. And I I just I I
there may be a handful of people who are
like that. I I don't you know, I don't
know. Um I I think it's more honestly
the other way around, which is uh the
you know, the more you're kind of
plugged into stuff in Silicon Valley,
the more important it is to make sure
that your kids actually fully understand
this and know how to use it. And that's
certainly the mode that we're in. And
that's that's certainly the mode that I
would encourage parents to think about.
>> I did not know your kid was
homeschooled. That is super interesting.
There it's almost a statement on, you
know, education in today's day. Maybe is
there any thoughts there? I'm just for
folks that maybe aren't in your tax
bracket that want to help their kids be
successful, maybe homeschooled, maybe
not. What what advice would you have?
>> This is the challenge and again this
this kind of goes to how you're you know
kind of your original question which is
education there's two completely
different ways to talk about think about
education. The way that's usually
thought about and talked about is kind
of at the level of like a nation, right?
So, so you know, it's like a national
level issue or maybe a state level issue
in the US, which is basically like how
do you educate all the kids? And of
course, that's incredibly important. And
of course, you're going to need like
some level of large scale system like
the, you know, the national K- through2
school system or something like that,
you know, in order in order to do that.
Um, but then there's this other question
which is like at n equals 1 for an
individual kid like what can you do with
with an individual kid? Um, and so I'll
just give you kind of the ultimate, you
know, kind of the ultimate answer to
that question, which is it's been known
for centuries that the ideal way to
teach a kid at the unit of n equals 1,
by far the ideal way to do it is is with
one-on-one tutoring. Like if you just
have an individual kid and the goal is
to maximize an individual kid, by far
you get the best results with one-on-one
tutoring. And and this is something that
like every royal family knew in history.
It's something that every aristocratic
class knew in history. There's all these
amazing examples. Alexander the Great
was tutored by Aristotle. He took over
the world, right? Like, you know, many
of the great kings and queens and you
know, royal families and aristocrats and
so forth, you know, over the course of
centuries. Um, you know, kind of always
had always had this approach. There's
actually also statistical evidence, um,
analytical evidence that this is
correct. Um, there there's this, you
know, massive question in the field of
education, which is how do you improve
educational outcomes? And basically it
turns out it's just it's very hard to
improve educational outcomes except
there's one method that always does it
which is called the it's called the
bloom two sigma effect which is there's
one method of education that routinely
raises student outcomes by two standards
of deviation and will take a kid from
the 50th percentile to the 99th
percentile and that's oneonone tutoring
right so again if you go back to like at
n equals one you have a kid and a tutor
and they're in this like you know very
tight loop with each other you know
where the kid is able to constantly kind
of be on the leading edge of what
they're capable of doing and they can
they you know they they can move
incredibly past and they get kind of
correction in real time, you get these
better outcomes. But, you know, to your
question, like it's never been
economically feasible for anybody other
than the richest people in society to be
able to provide one-on-one tutoring for
kids. AI provides the very real prospect
of being able to do that, right? Because
obviously now, right, if you have a kid
that's like super interested in
something and they can talk to, you
know, an LLM about it and they can ask
an infinite number of questions and they
can get instantaneous feedback. Um, and
in fact, you can even tell an LLM it's
like, you know, teach me how to do the
following. And you can say, you know,
wow, that's like I don't quite
understand what you're saying. Like,
dumb it down for me a little bit. Um,
okay, now quiz me, you know, do I
actually understand this? Like, people
can just do this today, right? Um, and
so I I think there's this like massive
opportunity for for parents, you know,
in in many walks of life to be, you
know, with with with a little bit of
time and focus, uh, to be able to say,
okay, you know, my my kid's probably
still going to go through a traditional
education system, but I'm going to
augment this with AI tutoring. Um, and
of course there, you know, and of course
there's going to be tons of startups,
right? And there already are that that
are going to try to build on all the all
the products and services for this. Khan
Academy, you know, on the nonprofit side
has a big push to do this. Um, and so,
you know, I think the the broad answer
might be a hybrid approach with schools
plus onetoone tutoring through AI. Um,
there's also this great, you may have
heard there's this great school new
private school system called Alpha, um,
in which everything I just described is
kind of the basis of their philosophy,
which is, you know, it's a combination
of in-person schools and teachers, but
it's also, you know, heavily based on AI
and AI tutoring. And so I I think
there's like a there is a magic formula
in here um that I think is going to
apply much more broadly. Um and I and it
really for parents interested in this I
now would be a great time to really
start to think hard about that um and
and to look at the options.
>> It's interesting because there's all
this concern that young people uh jobs
are not going to be there for them. AI
is replacing them. On the flip side,
there's what you're describing here. It
feels like people coming into learning
today are going to be move so fast and
learn so much more.
And where where do you sit on this
divide of like young people are in big
trouble or they're actually going to be
the ones winning in the end?
>> Yeah. So the job the job substitution
job loss thing is just it's very
reductive. It's it's I think it's an
overly simplistic model. And again it
goes back to what I said at the very
beginning which is we've actually been
in a regime for 50 years of very slow
technological change in the economy. And
so you know again like I said it's like
at a half the rate of of the previous
era and then a third the rate of like
100 years ago. And so we're we're coming
out of this kind of phase where we've
had like almost no technological
progress in the economy. We've had
remarkably little job turnurn as a
result of that relative to to any
historical period. And so even if AI
like ticks up, even if AI triples
productivity growth in the economy,
which would like be a massively big
deal, it would take us back to the same
level of job turnurn that was happening
between 1870 and 1930. And if you go
back and you read accounts of 1870 to
1930, people just thought the world was
a wash with opportunity. Right? at that
rate of technological transformation,
kids were able to like develop new
careers into new areas of of of the
economy, building new kinds of products
and services. I mean, you know, a huge
part of our of everything in our modern
world today was kind of invented and uh
and proliferated kind of during that
period. Um, and so even if AI like
triples the pace of economic change in
the economy, it's going to just
translate to like a much higher rate of
economic growth is going to transfer
translate to a much higher rate higher
rate of job growth. And you know there
there will be some level of like task
level and job level substitution that
will take place but that will be swamped
by the macro effects of economic growth
and innovation uh that will happen and
that then corresponding to that there
will be you know there there will be
hiring blooms you know I quite honestly
I think all over the place and then
again go back to the the other thing
which is like this is all happening in
the face of declining population growth
and and and increasingly population
shrinkage. Um and so human workers in
many many many countries over the next
you know 10 20 30 years are going to be
at more and more of a premium u
literally because you're going to have
shrinking population levels. You know we
don't really want to get into you know
politics particularly but it does feel
like the world broadly is going is is
going to reverse course on on on the
rates of immigration that we've had for
the last 50 years. it seems to be kind
of a broad-based you know kind of thing
happening um you know kind of with you
know rise in nationalism you know
concerns about the rate of immigration
and immigration historically in
countries like the US you know it's it's
kind of eb and flowed over time based on
kind of how you know kind of how the the
national mood shifts and so if you sort
of combine in a country like the US or
any country in Europe if you combine
declining population with less
immigration you the the remaining human
workers are going to be at a premium not
at a discount um and so I think I think
that combination of kind of faster
productivity growth, faster economic
growth, and then slower population
growth and less immigration. Um,
actually means there's going to be much
less of this kind of dystopian, you
know, no jobs thing. I I just think it's
probably totally outpaced.
>> That is extremely interesting. So, what
I'm hearing is you're not super worried
about job loss. Is the key here that the
timing kind of just works out, this
population decrease, you know, like all
these kind of have to line up for there
not to be this massive job loss with AI?
>> Yeah. Well, look, if we didn't have AI,
we'd be in a panic right now about
what's going to happen to the economy.
Right? Because what we what we'd be
staring at is a future of depopulation
and like depopulation without new
technology would just mean that the
economy shrinks. Right? So so it would
mean that the economy kind of itself
kind of shrinks over time. You know the
opportunity diminishes. There are no new
there are no new jobs. There are no new
fields. There's no new there's no new
source of consumer demand for spending
on things. Um and so you you would you
would you would be very worried about
going into period of like severe decline
of stagnation. Um, and you know, you
know, essentially you'd be looking at
these like very dystopian scenarios of
like an economy kind of self-
euthanizing itself uh over time. Um, and
and so you'd be very worried about like
the opposite of what everybody, you
know, thinks that they're worried about.
The only reason we're not worried about
that is because we now know that we have
the technology that can substitute for
the lack of population growth and then,
you know, also for the for the lack of
immigration that's likely. And so, you
know, I would say the timing has worked
out miraculously well in the sense that
we're going to have AI and robots
precisely when we actually need them,
uh, to keep the economy from actually
shrinking. Um, and and I just think like
that that's just like a a fundamentally
a fundamentally good news story. Um, to
get to the mass job loss thing that
people are worried about, um, on the
other side of things, you know, you have
to you'd have to look at like far far
far higher rates of productivity growth.
you'd have to look at rates of
productivity growth that are 10 20 30
50% a year, you know, something like
that, which are, you know, orders of
magnitude higher than we've ever had in
any in an economy in the history of the
planet. Um, you know, it's possible that
we get that. I mean, look, I'm, you
know, I I have my utopian kind of, you
know, kind of, you know, temptation
along with everybody else. If if AI like
radically transforms everything
overnight, then maybe you, you know,
let's let's play out the kind of utopian
scenario. Uh you get to a much higher
level of of of productivity growth. You
get to a much higher level of
technological change. corresponding to
that you'll have a massive economic
boom. Uh you'll have a you know massive
growth in the economy and then
corresponding with that you'll have a
collapse in prices. Um and so the price
of goods and services that are that are
that are sort of you know whatever you
want to call it affected by or
commoditized by AI the prices of those
goods and services will collapse right
there'll be price deflation and then as
a consequence of price deflation
everything that people are buying today
gets a lot cheaper and that's the
equivalent of a gigantic increase in
wealth right across the society right
think it this way this is actually worth
talking about because people I think get
get kind of sideways on on this issue so
if AI is going to transform the economy
as much as the you know whatever or
utopians or dystopians or whatever kind
of think that it will. The necessary
economic calculation of what happens is
massive massive productivity growth. The
consequence of massive productivity
growth, what that literally means
mechanically is more output requiring
less input, right? So you get more
economic output for less input, right?
So you're substituting in AI for human
workers or whatever. And as a
consequence, you get like this massive
boom in output which with much lower
input costs. The result of that is you
get lots of goods and services in all
those affected sectors. The result of
those gluts is you get collapsing
prices, right? The collapsing prices
mean that the thing today that cost you
$100 now cost you $10 and now cost you
$1. That's the equivalent of giving
everybody a giant raise, right? Because
now they have all this additional
spending power. That additional spending
power then translates to economic
growth, right? The development of new
fields. Everybody's like materially like
much better off very quickly. And then
by the way, if you to the extent that
you do have unemployment coming out the
other side of that, it's it's now much
cheaper to provide the kind of social
safety net to prevent people from being
emiserated, right? Because the prices of
all the goods and services that like a
welfare program has to pay from, they're
all collapsing, right? And so the price
of healthcare collapses, the price of
housing collapses, the price of
education collapses, the price of
everything else collapses because this
this this this incredible impact that AI
is having. And so in this kind of
utopian dystopian scenario that people
have, it's not there there's no scenario
in which like everybody's just poor. In
fact, it's it's quite the opposite,
which is everybody gets a lot richer
because prices collapse and then it's
actually much easier to pay for the
social safety net for the people who,
you know, for some reason can't find a
job. And so, like like maybe we end up
in that scenario. I mean, the the kind
of optimistic part of me says, yeah,
maybe AI is that powerful and maybe the
rest of the economy can actually change
to to accommodate that and maybe that'll
happen. But the result of that is going
to be a much better news story than
people think it's going to be. Um, and
again, everything I've just described,
by the way, is like just a very
straightforward extrapolation on very
basic economics. I'm not making any like
bold predictions of what I just said.
This is just like a straightforward
mechanical process that that that plays
itself out if you have higher rates of
productivity growth, which are
necessarily the results of higher grade
rates of technological growth. And so, I
think we're I think we're looking at,
and to be clear, I think we're looking
at a world that's not like radically
transformed the way that maybe the
utopians think that it will be or the
the dystopians think it will be. I think
it'll be more incremental for races we
can discuss. But I think that
incremental is overwhelmingly I think
that process is going to be a good news
process. And then even if it's much
faster, it's also going to be a good
news process. It'll just be a good news
process in the other way that I
described.
>> I love hearing optimism and good news. I
will also add that you've been I was
researching you ahead of this chat and
you've been right so many times about
where the world is heading. That's why
I'm especially excited to talk to you.
I'll give you a short list. I imagine
there are many more things. Uh okay.
Okay. So, one, you were right about the
web and web browsers becoming important.
You were right about software eating the
world. Check.
You uh in 2011, you said that in 10
years we're going to have 5 billion
people using smartphones. And I believe
the actual number ended up being six
billion.
You also you had this debate with Peter
Teal that I came across where you were
debating whether technologies stop
progressing or if new technology will
continue to emerge. and you were arguing
there is progress. Progress will
continue. And he he was like, "No, I
think we're done with cool technology."
You were right. Uh imagine there are
many more things you were right about.
So, so again, I'm just I I love hearing
your predictions because I feel like
they're actually going to turn out to be
correct.
>> So, I should start by saying I've been
wrong about tons of things, but you
know, I buried those out back behind the
shed.
>> Delete them from the internet. No web
browser can discover them.
>> Yes, I have them nuked out of the
internet archives so they they're never
seen again. Um, so, uh, you know, I'm
wrong plenty of times also. Um, but
yeah, I mean, look, I think, yeah, some
some of those I got right. By, by by the
way, I will say on the on the Peter one,
I I have come I've come much more around
to Peter's point of view.
>> Um, I would probably argue that one like
quite a bit differently today than I
did, and I would give his view I think I
think a lot more credit. Um, and and it
actually goes to kind of the discussion
that the kind of conversation we just
had, which is the the real form of what
Peter was arguing was we have lots of
process in bit. We have lots of progress
in bits, right? But we have we have very
little progress in atoms, right? Um and
and that's the real core of what he was
arguing. And I think I I I think I I was
a little bit I don't know missing that
or kind of you know kind of glossing
that over a little bit um because I was
so focused on making sure people
understood no there actually is still
progress happening in in bits. But I
think you know a lot of his critiques
around the lack of progress in Adams is
real and and again this goes back to
this thing of like in the and he you
know he's talked about this for a long
time. In the last 50 years there has
just been very little technological
innovation in most of the economy.
there's been very little technological
innovation in particular anything
involving atoms that you know there's
been very little real world
technological change there just there
just hasn't been like the the the built
world is just not that different today
than it was 50 years ago and if you and
again if you contrast that you know if
you if you compare and contrast 1870 to
1930 it was a dramatically different
world if you contrast 1930 to 1970 it
was a dramatically different world if
you contrast 1970 today it's not that
different right and look you just see
that you could just like walk around and
it's just like oh yeah there's a bunch
of buildings that were built built in
like 1960, right? And there's a bridge
that was built in like 1930 and there's
a dam that was built in like 1910 and
there's a city that was founded in, you
know, 1880 and like
what have we done, right? Like where are
new cities? Where are new dams? Where,
you know, where's where's the California
highspeed rail? Like you know, you know,
like what's going on here? And so like I
think he is I I think he is right about
a lot of that. Um, again, this is also
why I think that AI is not going to have
as rapid an imp. It's not going to be
again this kind of utopian or dystopian
view of like everything changes
overnight. I think it just kind of can't
happen because of the reasons that Peter
articulates which is there's just
there's so much about how the world
works that's basically just like wrapped
up in red tape like bureaucratic
process, rules, restrictions. um you
know the the the politics um by the way
you know unions cartels
opolies there there's all these
structures in the world that are kind of
economic or political or regulatory
structures that basically prevent things
from changing and so I mean let's take
let's take a great example like a AI's
impact on the healthare system like by
rights AI is going to have a dramatic
impact on the healthare system and in
and in in very positive ways but you
know large parts of the medical system
today are they are cartels, right? And
so there's like a there's the doctors
are a cartel and like nurses are a
cartel and like hospitals are a cartel
and then there's this push to like
nationalize all the healthare systems
and then you've got, you know, then
you've got a government monopoly, right?
And it's like and and and guess what
cartels of monopolies don't like is they
don't like like rapid change, right? Um
and so, you know, you show up as a kid
and you're like, "Wow, I've got like
this new technology to do like AI
medicine." And they're like, "Oh, well,
does it threaten Dr.'s jobs?" Well, in
that case, we're going to we're going to
block it. So, and I think a lot of
consumers, by the way, you know, I I I
see this in my life and you you'll
probably see this in your life also,
which is, you know, like Chet GPT is
like almost certainly a better doctor
than your doctor today, but like Chad
GPT can't get a license to practice
medicine, right? So, it can't substitute
for a doctor. It can't prescribe
medications, right? It can't, you know,
perform procedures, right? And so there
there there are these any anyway so
Peter Peter I think was very articulate
and has been for a long time on like no
there are actually real structural
impediments in the economy and in the
political system that we have that
actually prevent any the rates of change
that are anywhere near the rates of
change that people had in the past. And
and you can maybe say optimistically you
know maybe the presence of it of the new
of the new magic technology of AI maybe
it causes us to revisit a lot of these
assumpt assumptions for the first time
in decades to really say okay is this
really the world we want to live in?
Don't we actually want to get to the
future faster? So maybe that would be
the optimistic view.
>> It's time to build. Somebody famously
said, I uh in my calendar, I actually
have that as my when I start to work.
It's time to build. That's my block in
the morning of the day. Thank you for
that.
>> Okay. I love I love the way you go from
just like macro to just like end of one.
And I want to go to end of one. A lot of
the listeners of this podcast are
product managers. They're engineers.
They're designers. They're not a lot of
There's a lot of founders, but there's
also a lot of non-founders. There's a
lot of people building product that
aren't founders and uh obviously a lot
of people are worried about where their
career is going. Is one of these roles
going to disappear? Is one of these
roles going to do really well? How do I
stay up to date? You're close with a lot
of teams, a lot of product teams. What's
your sense of just the future of these
three very specific roles? Product
manager, engineer, designer.
>> This I think is a really funny question.
So these three roles in particular
obviously are kind of the central roles
for for building you know for tech
companies. So, the way I've been
describing it is, you know, you know the
concept of the Mexican standoff, right?
Which is the the movie scene where the,
you know, the two guys have guns
pointing at each other's heads.
>> Um, and then there's, if you watch like
John Woo movies, he loves to have he
does the three-way Mexican standoff
where you've got like a triangle, you
know, people like, you know, and of
course it's John Woo movie, they've got,
you know, guns in both hands.
>> So, they're all each each is aiming at
the other two.
>> Yeah.
>> Um, and you got this kind of standoff
situation. And so the way I've been
describing this is there's like a
Mexican standoff happening between those
three roles between product manager,
designer and coder. Specifically the
following which is every coder now
believes they can also be a product
manager and a designer right because
they have AI. Every product manager
thinks they can be a coder and a
designer. And then every designer knows
they can be a product manager, right?
And a and a coder, right? And so people
in each of those roles now, you know,
know or believe that with AI they they
don't need the other two roles anymore,
right? they they they can do that
because they can have AI do that. And
then of course and then of course
there's the real irony which is you know
all the the all three of them are going
to realize that AI can also be a better
manager, right? So they're going to
they're going to end up a aiming the
guns up the order chart. But that's
probably that's the next phase. And what
I think is so fascinating about this
Mexican staff is they're actually all
kind of correct I think right which is
AI is actually a pretty good you know
it's now it's actually now a really good
coder. it's actually now a really good
designer and it's also a really good
product manager, right? It's actually
good at doing all three of those things
or at least doing a lot of the tasks
involved in in in those three jobs. And
so again, this this goes back to the the
the superower this kind of idea of the
supermpowered individual. Uh where if if
I'm a coder like you know I mean step
one is like I need to make sure that I
really understand AI coding and like
what that means and what how coding is
going to change in the future. you know
that that I need to you know
specifically how to go from being a
coder who writes code entirely by hand
to being a coder who you know
orchestrates you know a dozen instances
of of of you know coding bots you know
you know there's there's a change in the
actual job of coding itself which is
which is happening right now but the
other part of it is okay how do I become
that superpowered individual how how do
I become a coder that also then
harnesses AI so that I can also be a
great product manager and I I can also
be a great designer right and then the
same thing for the product manager which
is how do I make sure that I can now use
coding tools how do I make sure I can
also, you know, do AI AI based design.
And the same thing for the designer,
which is how do I use AI to be be also
become a coder and also become a product
manager. And then what you get is maybe
the maybe the those individual roles
change like maybe those are not anymore
sort of stovepipe roles the way that you
know they have been for the last 30
years or whatever. Uh but what happens
is the the talented people in any of
those roles become superpowered and they
become good at doing all three of those
things. Um and then and then those
people become incredibly valuable
because then those are people who can
actually like you know build and design
right new products right from scratch
which is like the you know which is
which is the most valuable thing. And so
I I think I think that's I think I think
that's the opportunity.
>> So I love this answer. So what I'm
hearing is essentially uh if you're
amazing at any of these three roles you
will do well.
>> Number one if you're amazing at these
roles that's great but also you part
part of being amazing these roles is
also being being able to fully harness
the new technology right. So if you're
if you're a master coder today and you
you don't ever get to the point where
you you figure out how to use AI to
leverage your coding skills, you and and
do more, right? Like at some point you
are going to hit an issue, right? Here's
another way economists talk about this,
which is there's the concept of the job,
but the job is not actually the atomic
unit of what happens in the workplace.
The atomic unit of what happens in the
workplace is the task. And so and and
then what what the way the economists
think about it is a job is a bundle of
tasks. And everybody wants to talk about
job loss, but really what you want to
look at is is task task loss, right?
Tasks changing. I mean the the the the
classic the classic example of task
changing. Classic example of task
changing was once upon a time executives
never used typewriters or personal
computers themselves, right? You know,
if you were a vice president of a
company in 1970 or whatever, you did not
have like a typewriter or computer on
your desk typing things. You had a
secretary who you dictated memos to,
right? And then there and then there was
this change where like emails started to
show up. And what would happen was the
job of the secretary then went from, you
know, it went from, you know, the the
job of the secretary changed from
sending out letters with stamps on them
to like sending or receiving emails with
the other admins. And then and then the
secretary would print out the email and
bring it into the executive's office.
And the executive office would read the
email and paper, scroll scroll the reply
um and and and give and give that
message back to the secretary who would
go back and type it into the computer on
on on his or her desk and send it as an
email. Fast forward to today, none of
that happens. Now executives just do all
their own email. They still have
secretaries or admins, but they're now
doing different tasks. You know, they're
travel planning and orchestrating events
and like doing all these other things,
you know, that that you know that the
great admins do. And then and then the
task the task set ironically of the
executive has expanded to do actually
more of the clerical work themselves
actually like sit there and like type
their own memos, which again 50 years
ago they never never would have done
that. And so the executive job still
exists. the secretary job still exists u
but the tasks have changed and and I
think that's like a great example of
what's going to happen in coding the
tasks are going to change is what's
product management the tasks are going
to change designer tasks are going to
change and so the the the job can p the
job persists longer than the individual
tasks and then as the tasks change
enough then that's when the jobs change
and so at the at the level of individual
you kind of want to think of like okay I
have this job the job is a bundle of
tasks I need to be really good at making
sure that I can like swap the tasks out,
right? I can I can really adapt, use the
new technology, you know, get really
good at AI coding, for example. I can,
you know, and then and then you want to
kind of add skills. I can also get
really good at design. I can also get
really good at product management
because I've got this new tool. So, you
want to kind of pick up more and more
scope as you do that. And then, you
know, 10 years from now, is your job
title coder or coder designer, product
manager, or is it just I build products
or is it just I tell the AI how to build
products? It's like whatever that
whatever that job is called, who even
knows what it's going to be, but it's
going to be incredibly important because
the people doing that job are going to
be orchestrating the AI. And so that
that that's the track that the best
people are going to be on. Um and and I
think that that's the thing to lean hard
lean hard into.
>> I think people aren't fully grasping
just specifically software engineering
and how much that is changing. Like it's
pretty clear we're going to be in a
world soon where engineers are not
actually writing code, which I think a
year ago we would not have thought. And
now it's just clearly this is where it's
heading. It's like there's going to be
this artisal experience of sitting there
writing code which is so crazy how much
that job is going to change.
>> Yeah. So again here I go back and again
pardon maybe the history lesson but like
I go back like coding. So the first you
may know that do you know the original
definition of the of the term
calculator. Do you know what that
referred to?
>> No.
>> It referred to people.
Right. So back before there were like
electronic calculators or computers or
any of these things um the way that you
would actually do computing the way that
you would do calculating like the way an
insurance company would calculate
actuarial tables or the military would
like calculate you know I don't know
whatever troop logistics you formulas or
whatever it was the way that you would
do it is you would actually have a room
full of people um and by the way these
like big rooms you could have hundreds
or thousands or tens of thousands of
people doing this and you would actually
you would actually figure out you have
somebody at the head of the room who was
like responsible for like whatever the
mathematical equation was and then they
would parcel out the individual
mathematical calculations to people
sitting at desks who were doing them all
by hand, right? And and those that that
job title was those people were
calculators, right? Um and so we've gone
from a world in which you literally have
people doing mathematical equations by
hands by hand. Then we got the first
computers. The first computers of course
didn't have programming languages,
right? They they only had machine code,
right? So the first computers were
programmed with ones and zeros. And so
the task of the programmer became do the
ones and zeros and then that became
punch cards and you can still you know
there's still people you know kicking
you know today who you know whose job as
a programmer was to like deal with the
punch cards and then you got actually
this big breakthrough which was called
assembly language which was basically
the way to do machine code but like with
some level of like English kind of added
to it and then the best programmers did
assembly language and then you know when
I was coming up it was higher level
languages like C that compiled into
machine code and that's what programmers
did and then I still remember when when
scripting you know when scripting
languages you know we developed
JavaScript at Netscape and then you know
Python took off and Pearl and these
other scripting languages but scripting
languages you know took off in the in
the in the in the in the 2000s there was
this big fight in in the technical
community which is is scripting real
programming or not right because it's
it's like it's kind of cheating right
because real programmers write code that
compiles to machine code and like real
programmers like do like memory
management themselves and they do all
you know this this this whole craft of
writing writing uh you know writing
writing C code and you know these these
JavaScript or Python programmers are is
doing this kind of lightweight thing and
does it even really count as as coding
and of course the answer is yes it very
much counted and now most coding is done
with the scripting languages right um
which have you see my point the
scripting languages have abstracted away
like five layers of detail underneath
that that people used to do by hand and
they don't anymore and then and then
there's and then to your point like AI
coding is the next layer on that AI
coding actually abstracts away the
process of actually writing the
scripting code right and so in one sense
this is a really big deal for all the
obvious reasons but on the other hand
it's like okay this is the next layer of
the task redefinition under the job of
programmer right now what's the job of
the programmer it's to your point it's
not necessarily to write the code by
hand but what it is now is all right now
you know if you talk to the world's best
programmers today what they'll tell you
is oh my job is I'm sitting there and
I'm orchestrating 10 code bots right
coding bots that are running in parallel
right and and literally they sit there
and they shift from browser you know
browser to browser or terminal to
terminal and they're and they're they're
watch their their day their day job now
is kind of arguing with the AI bots
trying to get them to like write the
right code, right? And then and then
debug it and and fix the problems and
change change the spec and and do all
these things. And so now now the job of
the programmer is to argue with the
coding bots, but like if you don't know
how to write the code yourself, you
don't know how to evaluate what the
coding bots are giving you, right? And
so, you know, you asked about the 10,
you know, our 10-year-old is, you know,
super into computers and super into
programming. And what I'm what I'm tell,
you know, he's he's using claude and
chat GPD and co-pilot and all these
things. What I'm telling him is like,
look, and by the way, he lo coding. He's
on Replet all the time doing vibe
coding, you know, doing g doing games,
you know, he's sitting there, you know,
it's hysterical, right? Because he's
sitting there, it's a 10-year-old
basically who's, you know, spends two
hours at dinner arguing with an AI for
fun, right? Um, right. But but what I'm
telling him is, no, look, you need to
still fully understand and learn how to
write and understand code because the
coding bots are giving you code. If it
doesn't work or if it's not doing what
you expect or it's not fast enough or
whatever, like, you need to be able to
understand the results of what the AI is
giving you, right? in in the same way
that somebody who's writing scripting
language code does need to understand
ultimately how the microprocessor works.
Um, and so again, it's it's kind of this
upleveling of capability where you
actually want the depth to be able to go
down and be able to understand what the
thing is actually doing even if you're
not spending your day actually doing
that by hand. And again, I look at that
and I'm like, okay, now programmers are
going to be 10 times or 100 times or a
thousand times more productive than they
used to be, right? And and and that is
overwhelmingly a good thing. The the the
the tasks are definitely changing. The
nature of the job is changing. Um, but
are human beings going to be involved in
like in the coding process and
overseeing the the AI coding and all
that? And and the answer is of course
absolutely 100%. Like no question.
>> So you're in the camp of still learning
to code, still a valuable skill.
>> Oh yeah, totally. Well, again, if you
want to be one of these super Look,
look, if you just want to put your like
self on autopilot and like I can't be
bothered and I'm just going to have AI
write the code and it's going to
generate whatever it does and that's
fine and I'm going to be, you know, I'm
going to be if if the goal is to be a
mediocre coder, then just let the AI do
it. It's fine. The AI is going to be
perfectly good at generating infinite
amounts of mediocre code. No problem.
It's all good. If if if the goal is I
want to be one of the best software
people in the world and I want to build
new software products and technologies
that like really matter then yeah you
100% want to still be you want to go all
the way down you want your skill set to
go all the way down to the assembly to
assembly and machine code you want to
understand every layer of the stack you
want to deeply understand what's
happening at the level of the chip right
and and and the network and so forth by
the way you also really deeply want to
understand how the AI itself works right
because you want to right because if
people understand how the AI works are
able to they're clearly able to get more
value out of it somebody doesn't
understand how it works, right? I mean,
you're always more productive if you
know how the machine works, right? When
you use the machine and so yeah, the the
supermpowered individual on the other
end of this that wants to do great
things with the new technology, yes, you
100% want to understand this thing all
the way down the stack because you want
to be able to understand what it's
giving you, right? And and and when
something doesn't work or when something
isn't right, you want to be able to
really quickly understand why that is.
Um, by the way, again, this goes back to
education. AI is your best friend at
helping you learn all that, right?
because it's like, oh, I need to
understand, I don't know, like this
isn't fast enough. Um, I need to go I
need to figure out as a coder, I need to
figure out how to do a different
approach to memory management or
something. And you can be like, well,
you know, like I, you know, I
don't quite know how to do that. Okay,
AI, let's spend 10 minutes. Teach me how
to do this, right? Teach me what this
all means, right? So, all of a sudden,
you have this like incredibly
synergistic relationship with the AI
where it's also helping you get better
at the same time as doing a lot of work
for you.
>> By the way, I was going to say I was a
big Pearl uh programmer. I was an
engineer for 10 years and that was my my
language of choice.
>> You do you remember I don't know when
you were doing it but do do you remember
at the at least early on do you remember
did you ever did you ever hit this where
like coders were like looking down their
nose at you being like
>> for sure for sure it's like this is so
slow it's not going to scale what are
you what are you spending all your time
on this thing? Yeah, exactly. And of
course, you know, and again, it was sort
of this thing where, you know, they were
they were sort of correct, which is at
the beginning it wasn't, you know, fast
enough or whatever. By the end, they
were definitely wrong, right? Which is
it got much better, much faster, and you
know, it's it swept the world. U you
know, most coding today happens as
scripting languages. And and then by the
way, the people along along the way, the
people who really understood the
scripting languages and the people who
understood all the lower level systems,
they were the ones who were able to
actually make the scripting languages
actually work really well, right? And so
that that was that was a great example
of this kind of adaptation. And then and
then again the result of that was you
know a far higher number of people
writing code with scripting languages
than were ever writing code with lower
level languages. And I I think this will
just kind of be a more dramatic version
of that. I love that Pearl was designed
by a linguist. I don't know if you
remember that part and that's what made
it so nice to to code with.
>> Well that's funny because of course it
was so notorious for being impossible to
understand. So
how ironic.
>> Yeah.
>> This episode is brought to you by Data
Dog, now home to EPO, the leading
experimentation and feature flagging
platform. Product managers at the
world's best companies use Data Dog, the
same platform their engineers rely on
every day to connect product insights to
product issues like bugs, UX friction,
and business impact. It starts with
product analytics where PMs can watch
replays, review funnels, dive into
retention, and explore their growth
metrics. Where other tools stop, Data
Dog goes even further. It helps you
actually diagnose the impact of funnel
drop offs and bugs and UX friction. Once
you know where to focus, experiments
proved what works. I saw this firsthand
when I was at Airbnb, where our
experimentation platform was critical
for analyzing what worked and where
things went wrong. And the same team
that built experimentation at Airbnb
built EPO. Beta do then lets you go
beyond the numbers with session replay.
Watch exactly how users interact with
heat maps and scroll maps to truly
understand their behavior. And all of
this is powered by feature flags that
are tied to real-time data so that you
can roll out safely, target precisely,
and learn continuously. Data Dog is more
than engineering metrics. It's where
great product teams learn faster, fix
smarter, and ship with confidence.
Request a demo at dataq.com/lenny.
That's data dogq.com/lenny.
Coming back to these this kind of triad,
the other element that I hear more and
more of is just as is the skill of taste
and design and user experience. It feels
like that's a very hard skill to learn
and to me tells me design is going to be
much more valuable in the future.
>> Yeah, that's right. And again here this
this is a great example. So the again
the task level the the the the task
level of like design the perfect icon,
right, is going to be like all right,
the A's going to do that all day long.
is g give you a thousand icon designs.
It's going to be great. Like it's going
to be fantastic. Like whatever, you
know, and there will still, by the way,
there will still be some level of human
icon design or whatever, but like AI is
going to get really good at that. But
like what are we trying to do? Like the,
you know, kind of capital D design of
like, all right, what is this thing for?
And how does this how is this going to
function in a world of human beings? And
like, you know, what what's going to is
this going to make people happy when
they use it? Is it's going to make
people feel good about themselves? Um,
is it going to fit into the rest of
their life? Is it going to you know I
don't know challenge them in the right
way? You know all these kinds of higher
level questions that the great designers
have always thought about like that the
the job of designer right will involve
much more of those higher level more
important components and and then again
with with AI doing a lot more of the
underlying tasks. And so, you know, one
way to think about it is, you know, I
don't know, you you think of like, I
don't know, the world's best designers,
you know, Johnny Ibe or whatever, you
could be like, "Wow, like if I'm a
designer today, if I'm a 25-year-old
designer and I and I aspire to be, you
know, Johnny Ibean in a decade, um, it's
it's all of a sudden I have a new path
that I can use to kind of get to to get
there, which is I, you know, because
Johnny I did everything he did without
AI." Now, you know, a young designer can
be like, "Wow, if I really harness AI in
a decade, I'm going to be like the best
designer the world's ever seen because
it's not just going to be me. it's going
to be me plus being so super empowered
by this technology to be able to do so
much more. Um, and then so much more of
my time and attention is going to be is
going to be able to be focused on these
higher level things that most most
designers never get to. And I think that
that's going to be another great example
of that.
>> So maybe what I'm hearing here is kind
of this T-shaped strategy of be if you
want to be successful in any three of
these roles, be very very very good at
that specific role, product management,
engineering, design, and then get good
enough at these other two roles.
>> Well, so I think that's great. I think
that's really really relevant. And then
you know the Scott you know Scott Adams
unfortunately just passed away um you
know which which is a real tragedy but
um I was always I I referred for years
to actually Scott's Scott Adams he had
this famous um he had this famous kind
of career advice he would give people
which I I think makes a lot of sense
which which doveetails with what you're
saying which is he he used to say he
used to say it's like look he said um
you know I I could he he said you know I
could have been a pretty good cartoonist
um or I could have been like pretty good
at business but the fact that I was a
cartoonist who understood business made
me like spectacularly great at making
Dilbert,
right? Because even the world's best
cartoonist who didn't understand
business could have never written
Dilbert. And then the world's best
business people who didn't know how to
do cartoons couldn't have done Dilbert.
It took somebody who actually had both
of those skills to be able to make
Dilbert, right? Which is one of the most
successful cartoons in history, right?
And so so the the way Scott always
described it was that that the from a
career development standpoint that the
additive effect of being good at two
things is like more than double, right?
um the additive effect of being good at
three things is more than triple, right?
Um because you you you be you become a
super relevant specialist in the
combination of the domains. Um and and
you you look you see this all I mean you
see this all over you know you see this
all over the economy. Yeah. I mean you
see this all over the economy but I'll
you know give you an example Hollywood
you know just Hollywood as an example
you know there are a lot of writers who
can't direct a movie and they can be
very successful writers. There are a lot
of directors who can't write a movie.
They can be very successful directors.
But the superstars in the entertainment
industry are the people who can write
and direct, right? And you know they
they have a term for those. They call
those auras, right? And that's you know
those are the people who are like the
real creative forces that move the
field. And so and so again and by the
way Hollywood actually it's really funny
spend been spending a lot of time
talking to Hollywood people about AI.
Hollywood has the same Mexican standoff
going um right now that we that we
described in tech except in Hollywood
for example for filmm it's the director
it's the writer and the actor right
because the director is now thinking wow
I don't need the writer anymore because
the AI can write the script and I don't
need the actor anymore because I can
have AI actors the writer is saying I
don't need the director because AI can
direct the movie and the AI can do the
actors and the actor is saying I don't
need either one of these guys I can have
the AI direct the thing I can have the
AI write the thing and I'm just going to
show up and do my performance right and
so so it's it's it's the same it's the
same kind of tri triangular
configuration. And again, what what's
great about it is they're all correct,
right? Each person in each of those
three fields is going to be able to
expand laterally and pick up those other
those additional skills. And then as a
consequence, you're going to have more
people who can write and direct or write
and act or direct and act or do all
three. And and I think, you know, to
your point like your your your T-shift
thing, like I I think that's going to be
true basically across the entire
economy. And and and if you think about
the T is if you think about the T
configuration, it's like yeah, the bre
the breath the breath the top of the tea
is like how many individual domains are
you familiar enough with to be able to
use the AI tools to be able to do really
good work. And then the the this part of
the tea is how deep can you go in at
least one of those domains so that you
really really deeply know what you're
doing. But like if you're like super
deep on coding and you can use AI to do
design and you can use AI to do product
management, right? That that's your T
right there. and and you're a triple
threat at the top of the tea, but with
this level of technical grounding
underneath that. And I mean, at that
point, you're again, you're the
superpowered individual, you're going to
be able to just perform like feats of
magic, uh, for example, in terms of
designing and building new products, you
know, that people in my generation
couldn't have even dreamed of. And so I
I I think I think that this is a
universal kind of theory that I think
could can apply across the entire
economy.
>> I'm going to invent a new framework
right now. Okay, forget the T framework.
Uh, I'm picturing an F sideways or an E
where there's three two or three
I don't know, downward parts. And so
what I'm hearing is get good at least
two.
>> I think that's right. I think that's
right. Yeah. The combination. Yeah. Um
my my friend Larry Summers had a had a
different version of the Scott Adams
thing which is he he used to tell people
he said the key for career planning is
he said don't be funible,
>> right? And you know that's he's an
economist and so that was economics
speak and and what that means is what
that means essentially is don't be
replaceable. And so don't be a cog.
Right? So, and what that meant was don't
just be one thing, right? So, if you're
if you're if you're quote unquote, you
know, again, just a designer, it's just
a product manager, just a coder, like
then in theory, you can be swapped in or
out. But if if you have this if you have
this Yeah. to if you have this E or F,
you know, laying on it side kind of
thing. And if you have if you have this
combination of things that's actually
quite rare, then all of a sudden you're
not fungeible. Not not only you're not
funible, like you're actually massively
important because you're one of the only
people in the world who can actually do
that combination of things. Um, and
yeah, that that your ability now to
become one of those people is like just
titanically enhanced uh with AI as
compared to anything we've ever seen
before.
>> This is so interesting because I've
worked with people that are good at
these two skills and they were always
called unicorns at the company. She can
code and design. Oh my god. And what I'm
hearing here is this is what you need to
become. You need to become really good
at at least two things there. I think
you use the term smoke stack or
something where it's like PM over here,
engineer design. And what I'm hearing
here is you need to get good at at least
two of these skills. the silos of these
two roles are disappearing.
>> That's right. That's right. And again, I
can't I can't overstress the following
for for anybody listening to this. The
thing about AI that I think people are
just like not getting enough benefit out
of yet is just it will teach you.
Like this is amazing. Like there's never
been a technology before where you can
ask it like teach me how to do this
thing, right? So it's I always feel like
it's like it's like people spend too
much. It's one of these things where
it's like so much focus on figuring out
how to use like a large language model.
is like, okay, what am I going to try to
get it to do for me? Right, which is of
course very important, but the other
side of it is what can I get it to teach
me how to do, right? And it's it's just
as good at that, right? Um, and so
again, this is this level this level of
latent superpower like you know, people
who really want to like improve
themselves and like develop their career
should be spending every every spare
hour in my view at this point talking to
an AI being like, "All right, train
train me up like tell me tell
supermpower me, tell me how to, you
know, train me train me how to be, you
know, I'm a coder. Train me how to be a
product manager." It will happily do
that. It's it knows exactly how to do
that. You know, run me, you know, make
me problems, you know, make me
assignments, then evaluate my results,
right? And it will it will do that just
as happily as it will do work quote
unquote for you.
>> Two tricks I've heard along those lines.
One is uh to watch the output. What the
agent is doing and thinking as it's
doing the work. So, if you're not an
engineer, is just sit there and watch it
think and make decisions. And it's
almost become this like layer on top of
learning to code is learning to see what
the agent is doing and thinking because
that teaches you about architecture. And
the other is uh a couple podcast guests
have mentioned this. When you get stuck
and then you figure out how to unstuck
yourself, you ask it, "What could I have
done differently? What could I have said
that would have avoided this error in
the first place?"
>> Yeah, that's right. That's right. Yeah.
Look, on that first one, and this again,
this is what I'm doing with my
10-year-old. Yeah. Look, if if if you
ask an Yeah, this is this is a really
good point. So, if you ask an AI, write
me this code, and then and then it
doesn't and it comes back and it doesn't
work right. Like if if all you know is
like single function I asked and it gave
me back something that's not good like
what do you like what do you even do
with that right like you don't
understand why it gave you that result
do you really understand even what do
you even understand what to tell it to
try to get it to do something different
but to your point like if you actually w
if you actually watch what it's doing um
and and and then and then you you have
the grounding you know kind of that leg
of the of your ear or your F um if you
have that grounding then you can be like
oh I see what it's doing I see where it
made the mistake I see where it went
sideways and then you're all of a sudden
able to intervene and able to say no no
that's not what I meant do this other
thing right and so and again this is
this this this is a big part of having
having the actual kind of you know
synergistic relationship um is that you
understand and by the way look I mean
this is like everything I'm saying is
you know everything everything that
we're saying right now also is the same
as if you're working with human beings
right like you know if you and I are
colleagues and I you know ask you to do
something you'd come back with something
completely different like I I do need to
understand what was happening in your
head right in order to in order to be
able to get do need to give you give you
feedback right if I just tell you oh
that's wrong it doesn't like nothing
happens. I need to actually understand I
need to have theory of mind, right? I
need to understand what you were
thinking in order to really give you the
right feedback. Um and so and and you
know and again the great thing with AI
is AI will happily sit there and explain
all day long why it's doing what it's
doing. It'll you know it'll happily
critique itself.
You know, you can do this. By the way,
this has a very fun thing where you can
have have one AI critique the other AI,
right? Um, which is another thing, which
is like you have one AI write the code,
you have another AI debug the code, and
so you can actually use you can play the
AIs off against each other and get them
to argue with each other. Um, and yeah,
the these are all these are all the
kinds of skills that are going to
become, I think, incredibly valuable.
>> I think people call those LLM councils.
Yes.
>> They're talking to each other.
>> Yeah, that's right. That's right.
>> I do feel like if I were like I'm I have
no design background. I've always wanted
to design. I would I've always wanted to
be a great designer. Uh, it feels like
that's the hardest one to learn of all
these three by just watching and
talking, right? Because there's a lot of
exposure hours as as folks have used
this term just like how do you learn to
be a great designer? That feels like
that's going to be really hard and
valuable.
>> So, my my true confession is I've always
kind of wanted to be a cartoonist,
>> but I have no like art skills,
but as we're talking, I'm like, it might
be time.
>> Their time has come, Arc.
>> Yes.
>> I want to pivot to founders, your maybe
your bread and butter. You spent a lot
of time with the most cutting edge AI
forward founders. I'm curious to what
you see them do, how you see them, some
way they operate that's maybe blowing
your mind about how the future of
starting a company looks, how the future
of AI forward companies look.
>> Yeah. So, this is a great very, you
know, topical topic that's all playing
out in real time right now um on on the
leading edge. So, I I think there's like
three layers of it and see see if this
makes sense. I think there's like three
layers of it. I think layer one is
they're thinking all right how how does
AI redefine the products themselves
right um and and this is kind of the
this is kind of the timehonored you know
kind of thing that happens at technology
transitions and this is kind of what you
know a lot of venture capital is based
on which is um you know okay there's a
new technology that comes out and you
know maybe it's the personal computer or
the iPhone or the internet or now it's
AI and it's like all right um is this a
new capability that gets added to
existing products right so all of a
sudden you've got I don't know an
existing you software business and now
you got your you know PC version of it
and now you got your iPhone version of
it and you just kind of keep on going
and you know you kind of add the new
technology kind of gets kind of added
into the mix um you know it's kind of
another ingredient into an existing
formula and and of course you know a lot
of new technologies are like that right
um you know I don't know when I don't
know when flash when flash storage came
out or something you know it didn't
really you didn't really redefine the
the software industry because people
just went from using you know hard disk
using flash storage or something um uh
but when the internet came out like
basically old school onrem software for
the most part you know not not entirely
but like a lot of it died and just got
replaced by like web software um right
and so so sometimes you get the kind of
it's additive to an existing thing
sometimes you get the actually it
redefineses an entire product category
redefineses an industry the actual you
know in many cases the companies
themselves turn over and so so so you
know so there's sort of this question
and like you know an example you just
mentioned nano banana so like a great
example is there you know there are
these businesses like you know just take
Adobe like you know Photoshop is built a
whatever a 40-year franchise in image
editing. Um, okay. Is AI a sort of a
feature now that gets added to Photoshop
to be able to do AI based image editing
or, you know, do you just like stop
editing images entirely because you're
using Nano Banana and your all images
are just being generated and it's just
easier to just have AI generate a new
image than it is to try to edit edit an
old one. So I think you know there's
many areas of of tech in which that
question is being asked and you know the
answers I think will vary by domain but
u you know obviously as as a venture
firm we're batting hard on many of these
categories being being totally
reinventsted and a lot of the a lot of
the best founders are trying to figure
out how to do that. So that so that's
kind of AI you know changing the
definition of the product. I think the
next layer is actually a lot of what
we've already talked about which is AI
changing the jobs. Um, and so it's, you
know, a lot of what we've already talked
about, but like, okay, if I'm a founder
of a company and I've got, you know, if
I have, you know, room in my budget for
100 coders, you know, how do I get those
coders to be super empowered AI coders,
not, you know, not the kind of coders I
used to have? And if they're super
empowered AI coders, then does that
mean, you know, do I still need the
hundred? Maybe now I only need 10. Or
does that mean I still want 100, but now
they're doing 10 times more, right? And
so that, you know, as you know, like a
lot of the best founders are are working
on that right now. And then I think the
third shoe to drop hasn't quite dropped
yet, but it's it's you know it's kind of
the big one which is like all right like
the the the the basic idea of having a
company right you know does that change
and and again here you've got this
concept of the superpowered individual
which is like okay um you know can you
have entire companies where you have
basically the founder does everything
right because what the founder is doing
is like overseeing an army of AI bots
and and there's sort of this you know
there's kind of this holy grail in our
industry that's been running for a long
time which is like can have the can you
have like the one person billion dollar
outcome and you know we've had a few of
those over the years Bitcoin is probably
the most spectacular example you know
with Ethereum right behind it um you
know which wasn't quite one person but
you know a very small team you know you
had you know kind of Instagram and
WhatsApp that had very big outcomes with
very small teams you know every once in
a while you get one of these things
where you just you know some something
hits and you just have a you know very
small number of people associated with
it you know but that said you know most
most software companies obviously end up
with you know huge numbers of employees
um and So I I think you know some the
most leading edge founders are thinking
of like okay how how do I reconstitute
the actual varied definition or idea um
of a um of having a company and and you
know can you have a company that's
that's literally basically just all AI
um and so and and if you're doing so you
know if you're doing anything in the
real world that's hard but if you're
doing software like that that that seems
like it might be feasible in some cases
and then you know there's like the
ultimate example of that which is like
you know can you have like AI can you
have like autonomous like AI economy
stuff happening where you have like AI
bots on the blockchain or something you
know that are out basically out there
like functioning as a as a as a business
and like making money and just you know
literally where the the AI does all the
work itself and just get you know issues
me dividends and so you know maybe that
that you know maybe that maybe that's
the the final outlier result we have we
have a few founders who are chasing that
kind of thing. Um so I would describe
that as I would describe that as kind of
the the latter that the best founders
around.
>> Super interesting. this whole idea of a
oneperson billion-dollar company. I
think it depends on your definition of
what this is like an outcome I could
see. Uh having run running my newsletter
uh as one person with some contractors,
there's so many little annoying things
that I have to deal with with just
support tickets and issues and bugs and
like it's hard for me to imagine
actually a oneperson billion-dollar
company even if AI is handling so much
of your support because there's just so
many random edge cases that I'm just
const like filling out forms. Uh and so
I guess depends on do you have
contractors? Does that count? You know,
like what does it count? What does it
mean to be a one person? But I'm just
like I can't see that happening.
>> Yeah. I mean, look, Bitcoin's Satoshi
pulled it off.
>> But like, you know, the open source
community, you know, like does that
count? I don't know. I guess I guess
guess it counts. Okay.
>> Yeah. Exactly. Right. So, yeah, that
that Yeah. And I would say I don't
propose to have answers here, but more
just like
>> the smartest people I know are are many
of the many of the smartest people I
know are are thinking hard about this.
>> Yeah. What do you think about Moes? a
big question constantly in AI, you know,
the fact that everything's changing.
Just what's your guys' thesis on Moes in
AI? Does is that even a thing? Do you
care?
>> My experience with like really big
technological transformations, and of
course, I I kind of lived this directly
with the internet, and I saw this
happen, is the really big technological
transformations, they they take a long
time to play out, and there's there's
all of these structural implications
that just kind of cascade out over time.
And then there's kind of this this
there's this like rush to judgment up
front where people kind of say, "Oh,
it's therefore obvious that you know
XYZ. It's therefore obvious that this
kind of company is going to be the
company of the future, not that kind.
It's obvious that this incumbent is
going to be able to adapt and this other
one isn't. It's it's obvious that
there's economic opportunity and this
kind of startup and not in these others.
Um it's obvious that the moes are going
to be in this area of the technology but
not in this other area. And and there
and you know what everybody does is they
they kind of state those things with
like just an enormous amount of self
assurance where they they you know where
they really sound like they have all the
answers. And then you know what happens
is this these these ideas kind of
saturate the media right because the the
media naturally prizes like definitive
answers over open questions because you
know you want you know like when CNBC is
like booking guests they want a guest
who's going to come on and say yes this
is the way it's going to be X not like
you know I think that's a really good
question and let's like debate it from
like eight different angles. And what I
found is if you look back on those
predictions a few years later and you
you can do this by the way if you pull
up like coverage of the internet from
like 1993 through like 1997 or even
through like for that matter even
through like 2005 or 2010 and you look
at like the kinds of confidence
statements people were making in the
first 10 or 15 years like I would say
like almost all of them were wrong again
generally like quite badly wrong and so
I just I think the process I think with
massive with there's going to be a
massive amount of technological change.
It's going to be like I don't know five
or six layers of like structural change
that will play out over time and and
again a lot we've talked about a lot of
this but like it the implications on
like what are the definition of products
what are the definitions of companies
what are the definitions of jobs what
are the definitions of industries how
does this play out at the national level
how does this play out at the global
level you know how does this inter by
the way how does this intersect with
politics how does this intersect with
you know unions how does this intersect
with you know war you know what's China
going to do um you know uh and So it's
just like there's just there's there
just a tremendous number of unknowns
like a
very very large number of unknowns and I
think it's just like really really
dangerous to prejudge these things and
so I'll just give I'll just give and
it's just I'll just run this as a
thought experiment you know see what you
think on this but it's like you know
like do do AI models the are AI models
themselves like defensible like is there
a moat uh on AI models and on the on the
one hand you'd be like wow it certainly
seems like there is or should be Because
like if something takes you know
billions of dollars to build um and you
need you know you need this like
incredible critical mass of like comput
and data and there's only a certain
number of engineers in the world that
know how to do this and you know they
are getting paid like NBA stars um and
you know and then these companies have
to deal with all these like crazy you
know political issues and press issues
and reputational stuff and regulatory
and legal like all of that translates to
like you know okay probably at the end
of this there's going to be two or three
companies that are going to end up with
like you know 100% you know I don't know
whatever 5050 for 30 3030 or 90101 or
whatever it is market share and then
they're going to have whatever
profitability they have and it's going
to be a kind of a classic igopoly and or
or maybe you know maybe one company's
going to definitively it'll be it'll be
a monopoly and that and by the way those
outcomes have happened in software many
times before and so may maybe that that
will be the outcome you know the other
side of it is you know if you had told
me three years ago um you know that in
the uh you know kind of Christmas of
chat GPT that like within basically a
year to year and a half there would be
you know five other American companies
that would have basically basically, you
know, exactly capable products. Um, and
then there would be another five
companies out of China that would have
exactly capable products and then there
would additionally be open source that
was basically the same. Um, I would have
been like, wow, like it, you know, the
thing that seemed like it was Blackmagic
all of a sudden, you know, has has
become like commoditized really fast,
you know, which which by the way is
exactly what happened, right? Like, you
know, within within a year of GPT3
coming out, there were their open source
GP3s running on a fraction of the
hardware, right? That were available for
free. Um and then there were and then
you know there were five you know now
now you've got you know in the game you
know fully in the game you've got Google
and you've got Anthropic and you've got
XAI and you've got Meta and you've got
you know all these other companies that
are and then DeepSeek and you know Kimmy
and all these other Chinese companies.
Um and so like even at the level of like
LLMs or you know AI models like you can
squint and make that argument either
way. By the way same thing at the level
of apps right it's like you know one
school of thought is you know the apps
apps are not a thing because like the
model's just going to do everything. Um
but another way of looking at it is no
actually like actually adapting the
model as kind of the engine into a into
a domain involving human beings u where
you need to like actually have it fit
for purpose to be able to function in
the medical industry or the legal
industry or you know or whatever u or
coding you know no you actually need
like the application level is actually
going to matter enormously and maybe the
LLM's commoditizing maybe the value goes
to the apps um and and and again you can
kind of squint either way on that one
and I and I know very smart people who
are on both sides of that argument um
and so I my honest answer on this is I
think we're in a process of discovery
over time um which is you know in the
way I think about this kind of
structurally is it's a complex adaptive
system the technology itself you know
provides one of the inputs the legal and
regulatory process you know is another
input um in you know actual individual
choices made by entrepreneurs um you
know matter a lot um you know the
economics matter a lot availability of
investor capital varies over time that
matters a lot um and this is a this is a
complex system and so we we actually
don't know the the outcomes on this yet
and and we need to basically be we need
to be open to surprises at the
structural level uh of what happens and
of course as a as a VC this is very
exciting because it means we you know
we're doing this now we should kind of
make bets along every one of these
strategies um and kind of see and see
how this plays out and I just say like
there may be like one I don't know there
may be like one particularly brilliant I
don't know hedge fun manager or
something who has this all figured out
but I I guess I would say if if if they
exist I haven't met them yet.
So what I'm hearing here is don't over
obsess with moes at this point because
we have no idea what it'll end up being
and as much as it may feel like okay
there's no way OpenAI will lose this
lead clearly we're seeing a lot of
competition GPT rapper point is really
great a lot is such a derogatory term I
don't know year ago just like you're
just GPT rapper now it's like the
companies that are the biggest companies
fastest growing companies in the world
>> yeah well it's it's like a little bit
like I don't know I mean even just like
with you know you know the you know this
has been the you know the the holiday if
you know three years ago was the holiday
of Chad GPD this last, you know, month
or whatever has been the holiday of of
Claude, particularly Claude Code, right,
for for coding, but it's like, you know,
it's pretty amazing because it's like,
okay, there was Claude, which is, you
know, obviously a great accomplishment,
but then there's Claude Code, which
which is an which is an app, right? It's
a cloud rapper,
>> right? It's, you know, agent harness.
Um, and then um and then they did this
amazing thing where they came out with
was it co-orker?
>> Co-work.
>> Co-work um and uh and remember they said
coowork, which is a club code wrote
co-work in a week.
>> Yeah. A week and a half. Yep. 100%.
Well, and that's and there's two ways of
looking at that, which is like, wow,
that's really imp obviously that's
really impressive that cloud code was
able to build co-work in a in a week and
a half. That's great. That's amazing.
The other way to look at it is co-work
was developed in a week and a half like
like h how much complexity could there
be? How much of a barrier to entry can
there be in something that was developed
in a week and a half? And so and and
then you know and then again it's this
it's this it's this push and this pull
thing where it's like it's like wow it's
incredibly val it's incredibly
functional incredibly valuable and
people are like all over the world every
day now are like wow I can't believe
what I can do with this is like the most
magical product ever but at the same
time it took a week and a half right and
so right and so every other every other
model company you know I'm sure you'd
have to expect is sitting there being
like okay obviously we need to build you
know an Asian artist and then obviously
we need to build a co-work you know
thing for for for regular people and
obvious you know I I don't I'm not even
saying I know anything, but just like
obviously they're all going to do that,
right? Um and so, you know, how
defensible is that? And you know, in six
months, you know, and we've seen this
happen before, like in is quad code
going to get lapped the same way that
you know, GitHub copilot got lapped. You
know, the the history in the last three
years has been everything that looks
like it's like the fundamental
breakthrough gets gets basically
replicated and lapped very quickly. Like
many of the smartest people I know in
the field when I when I really kind of
talk to them kind of, you know, get a
couple drinks into them, they're like,
"Yeah, they're basically, you know, one
theory is like there really aren't any
secrets among the big labs." like the
big labs kind of all have the same
information and they kind of have all
the same knowledge and they you know
they're kind of they lap each other on a
regular basis but you know there's not a
lot of proprietary anything at this
point and then and then you know again
evidence of that is you know deepseek
you know came out of left field and
basically was like a you know
re-implementation of a lot of the ideas
under American big labs and you know and
had some original ideas of its own um
but like you know wow it wasn't that
hard for you know some you know
basically a hedge fund in China to do it
and so like how much defensibility is
there but on the other side of it you've
got wow all these big labs are now
paying you know individual engineers
like they're rock stars um and they're
you know incredibly bright and creative
people um and you know maybe there's you
know a dozen nent ideas in any one of
these labs that it's actually going to
be a huge breakthrough that's going to
be hard to replicate and so again it's
just like I think we just need to I
don't know my views I my view I need to
put like a big discount on my
forecasting ability on this one like it
for me it's much less interesting to try
to say okay as a consequence industry
structure in five years is going to be X
the big winner in the category is going
to be company Y the big you know product
killer app is going to be It's like I
this is to say I don't think I can
predict that. Um I I think I I think a
much much better use of my time is is
being being very flexible and adaptable
at a time like this.
>> So with all this in mind, do you feel
like there's something you're paying
attention to more to help you decide
okay this is where we want to place our
bet or is the answer essentially the
strategy you guys have which is place a
lot of bets. You guys raised the the
largest fund in history. Is that is that
the way you win in this world?
>> Yeah. So for I mean for us yeah for for
us we have we obviously have a very very
deliberate strategy. One one way to
think about this used the Peter Teal for
you remember the Peter Teal formulation
of uh he said there's a two by two
there's optimism and pessimism and then
there's determinant and is it
indeterminate and indeterminate right um
and so um and he always argued that like
there's he always argued that like
Silicon Valley is characterized by in
too much what he calls indeterminant
optimism right and what he what he what
he always described what he meant by
that is basically um I think the way he
would describe it is an indeterminant
optimist who thinks the world is going
to be better but can't explain are right
like some combination of things is going
to happen to make the world be better
even if we don't know what those things
are and and you know I think he he at
least historically would say like that's
that's basically you know that that that
that risks at least being just like
wishful thinking or delusional thinking
and what the world needs more is
determinant optimists which are people
who are like no the world is going to be
better because I'm going to do this
specific thing right and he would
classify for example Elon you know he
would s sort of maybe say you know VCs
are indeterminant optimists um and then
he would say you know Elon is the
determinate determinate determinant
optimist where it's like no I'm going to
build the electric car and I'm going to
you know solar and then I'm going to do
you know Mars you right and I'm these
very concrete things and I I think
there's a lot I think there's a lot to
Peter's framework but the way I would
describe it is I I think maybe he and I
if you disagree with part of that it
would be I think the indeterminant
optimism is a stronger phenomenon than
at least I think he's historically
represented it as and I would put myself
firmly in the indeterminant optimist
category and that's the strategy that we
that we have at A6Z which is and and the
reason for that is It's not hopefully
it's not so much wishful thinking. It's
more no what the indeterminant optimism
of venture capital or the indeterminant
optimism of A6Z or Silicon Valley is
very it's actually very specific which
is there are these extremely bright and
capable people like Elon and many others
who are founders right and product and
you know kind of product creators right
and and and each of those individual
people is a determinate optimist like
each of them each of them individually
has like a very strong view what they're
going to do but the great virtue of the
capitalist system the great virtue of
the American economy the great virtue
Silicon Valley is we don't just have one
of those and we don't just have 10 of
those. We have a hundred and a thousand
and then 10,000 of those and and the way
to optimize the outcome is to have as
many of those as possible be as good as
possible. Run as hard as possible and
and then just the the nature of you know
the nature of the future is like we just
don't know all the answers and that's
okay and then and the right way to deal
with that is to run as many experiments
as possible and have as many smart
people try to do as many interesting
things as possible. Um and so yeah, I
would I would put myself firmly on the
side of the indeterminate optimist. I'm
uh I'm wondering if the answer to the
question of what you look for now more
and more is this determinate optimistic
founder. Yeah. That has this massive
ambition and is actually working on
achieving it.
>> Yeah. Yeah. No, that's right. That's
right. I mean, look, the founders need
to be deter determined optimist. Like
they need to have a very specific plan
now. And look, the the critique the
critique always, you know, the critique
from the founders is, oh, UVC's have it
easy because like you don't have to like
you don't actually have to commit,
right? You don't actually have to like
make you you don't actually have to
like, you know, you don't have to make
the bed you lay in. You can like place
multiple bats. you can operate a
portfolio, you know, you should have a
lot more sympathy for us as founders,
you know, because we, you know, we only
get to make the one bet. Um, you know,
and there's there's truth to that. You
know, the counter-argument on that is
the founders get to run their companies.
We don't. So, so, you know, we we don't
we don't get to put our hand on the
steering wheel. And so, you know, the
great virtue of being a determined
optimist is you actually get to get to
single-mindedly execute against that
goal. And and and you look, in the long
run, who who does history remember?
History remembers Henry Ford, right? not
you know whoever was the you know
whatever the seed investor who seated at
Ford Motor Company and you know 10 other
car companies have failed right um and
so you know the determinant optimist is
the per you know the founder is the
founder and the company builder and the
engineer I mean these are the people who
actually do the thing and you know
deserve 99.99999%
of the credit but uh you know having
said that I I do think there is a role
for having having some indeterminate
optimist in the uh in the background
helping along the way and helping keep
the whole the whole cycle going
>> do you think about AGI in shifting your
investment thesis like as we approach
AGI and hit AGI as an investor, how do
you think about your investment thesis
changing?
>> Yeah. So, I've always kind of had a
little bit of an is I've always kind of
struggled with the concept of AGI um
because it at least well there there's
those defined terms which is where I
kind of struggle with it which is
there's like the prosaic there's the
there's the prosaic uh definition of AGI
and then there's like the I don't know
cosmic definition and the way I would
describe it as well let's start with the
cosmic one. So the the cosmic one is
basically it's the singularity, right?
Um and so AGI is the is the moment where
you enter the singularity, which is to
say that where the world fundamentally
changes and like the the rules of the
old world are gone. We're now operating
in a new domain and then you know the
kind of the full definition of
singularity is like it's a world in
which you know human judgment is no
longer really relevant because the you
know you get this self-improvement loop.
The AI the AI is improving itself and
it's sort of racing you know so-called
takeoff scenarios. you can see at this
takeoff thing where the AI is improving
itself and the machines are making
decisions so much faster than people and
people are just sitting there watching
the the machine do its thing you know
and I kind of described I don't really I
don't really think that's I don't I
don't think we live in that world like
whether you could call that utopian or
dystopian like I don't think we're lucky
or unlucky enough to live in that world
we could debate that we can talk about
that more but um the the the pros
definition of AGI that at least I think
the industry participants have kind of
converged on and tell me if you agree
with this is uh it's when the AI can do
every economically relevant task as good
as a The way um the co-founder of
Anthropic put it is like a basket of the
most valuable economic task. So it's
like 10 15 not every single economically
valuable task.
>> Okay. Got got it. Yeah. So it's maybe
even a slightly reduced slightly reduced
definition. Um and by the way we're you
clearly getting close to that if we're
not already there.
>> And so on that one I kind of feel like
so I kind of feel like the cosmic one
overstates what's going to happen. And
then I kind of feel like the kind of AGI
definition that you just gave I think it
kind of understates what's going to
happen. like it's almost too
reductionist and and the reason for that
is I don't think there's any reason to
assume that human skill level is the cap
on anything right and so the way we say
that is AGI always is you know the
definition you gave the definition I
gave it's kind of in it's always kind of
relative in comparison to a human worker
right and it's like I don't know like
human skill level caps out at a certain
point but that's because of the inherent
like biological limitations of the human
organism right like we're you know human
I give you example human IQ human IQ Q,
you know, kind of what they call fluid
intelligence or the the sort of G factor
of kind of uh, you know, fluid
intelligence. Uh, IQ, I think, tops out
in in humans as a species, it tops out
around 160, right? Where at at like 160,
it's like Einstein level, Einstein,
Fineman IQ,
>> in terms of IQ. Like, you just tops out
at 160. The the 160 IQ people are the
ones who come up with new physics.
There's only a small handful of those.
the generally speaking when we run into
somebody in the world who's like
incredibly smart who's like a
best-selling author or like a you know
one of the world's best I don't know
research scientists or one of the
world's best doctors you know or
whatever um it would be probably 140 um
is kind of the IQ that you're looking
for there. Um if you're looking for like
a really good lawyer it's probably 130.
Um if you're looking for like a really
good like line manager in a business
it's probably 110. um you know if you're
looking for like an accountant like a
small business accountant who's good at
doing the books for small businesses is
probably 105 right and so the the kind
of scope of like impressive human you
know the the the ability of the human
organism to do intellectually impressive
things you know it's sort of that 110 to
160 is kind of the spectrum and you know
good news is there's a lot of those
people running around but like there's
not that many at 140 150 160 but it's
like that's just that's like the
limitations of what can fit in here
right and it's like there's no
theoretical limit on where this goes if
you release the limitations of human
biology, right? And so can you have a
you already have people running these
experiments to kind of do human
equivalent, you know, kind of IQ uh uh
you know, for for existing AM model. And
by the way, existing AI models right now
are kind of testing around the 131 140
level, which means they're going to get
to the 160 level and they're, you know,
they're arguably on the mass high
starting to get to the 160 level now.
But like I I think we're going to have
AI models relatively quickly that are
going to be like 160, 180, 200, you
know, 250, 300, by the way. And I think
that's great, right? Like I feel I feel
I feel as great about that as I do about
the fact that we occasionally get an
Einstein, right? It's like would the
world be better off or worse off with
more or fewer Einsteins? And the answer
is of course the world would be better
off with more Einstein. And of course
the world would be better off with
machines that have IQ, you know, more IQ
like Einstein are greater than Einstein.
But like I think IQ's IQ of the machines
is going to exceed that in the humans. I
think that's that's really good. Um, and
then the performance, you know, again,
it goes back to like the AI coding thing
is happening. The performance against
task is going to get better also. Like I
I think, you know, this is where Line of
Stars in particular is like, yeah, okay,
like this thing is starting to generate
better code than I can. Okay, so now
we're going to have AI coders that are
actually better coders than the best
human coders. I think that's great. I
think we're going to have AI doctors
that are better than the best human
doctors. I think we're going to have AI
lawyers that are better than the best
human lawyers, which actually is going
to be very interesting to see. Uh, which
we can talk about, which I think is also
great. Um, and so like I don't think
there's a I think we're used to living
in a world where we just don't
understand how good good can get because
we've been capped by our own biology and
we're going to get to experience what
it's like when you have the capability
at your fingertips that's actually
better than human in these domains. Um,
and so I I you see what I'm saying which
is like I think this idea of like human
equivalent is just going to be like a
footnote. It's like, oh yeah, that was
just on Tuesday, you know, in in 2026 is
when they hit that and it kind of didn't
matter because the the next question was
like, okay, what are we gonna what are
we gonna what do we get to do in a world
in which we actually have machines that
are better than that, right? And so so
so I think this is going to be much more
of an exploratory process for actually
exceeding human capability than it's
going to be any sort of particular
singular singularity moment or whatever
that happens just that just happens to
coincide with the human threshold.
>> 200 IQ. I uh just like that frame of
reference is such a uh mindexpanding way
to think about just how fast and how
smart these things are going to get and
and quickly.
>> Well, I don't know if you have this
experience. I I have this experience all
the time. Well, two two experiences I
have all the time. One is just like I'm
just like like I know I ought to be able
to do this, but like I just can't like
it's going to take too long. You know, I
I want to write this thing or I want to
like whatever. I want to have this
theory on this thing or I have a plan or
whatever. And it's just like like I
I don't have the eight hours or or by
the way the eight weeks or the eight
years, right? And like I just don't know
enough yet and I'm just like I can't do
the math in my head and my memory isn't
perfect and like I can't remember and I
read you know after you had this you get
interested in something you read 10
books and then you're like I forgot
almost everything that I just read. Like
I I wish I could retain it all but I
can't. It's just like I you just have
this I I sort of live in this kind of
state of like endless frustration. So,
it's like I like if I could just be
smarter than I was, like I'd be so much
better at what I do, but I'm not. So,
so, so there's that. And I don't know
how often you have this, but I have this
on a regular basis. It's just like, you
know, I, you know, because of what we
do. Like, I know a bunch of people who I
know for sure are smarter than I
am. And I know it because when I talk to
them, I just find myself at a certain
point, you know, it's like for the first
half of the conversation, I'm just
taking notes the entire time. And for
the second half of the conversation, I'm
just like, Like, me. like
this person is just smarter than I am
and they're just outthinking me and
they're going to keep outthinking me and
I just can't and I'm just like all right
god damn it like I gotta go home and I
gotta like have a drink because I'm just
not, you know, I'm just not whatever
that is. I'm not that. And so we're just
so used to having those limitations
um that the idea of having machines that
work for us that don't have those
limitations. I I just I think that's
much more exciting than people are
giving you credit for.
>> Oh man, I could talk to you for for
hours, Mark. I'm thinking to close out
the conversation, I want to ask about
your media diet and your product diet.
You just talked about books, reading 10
books. I I think you famously read
constantly. I saw a interview with you
where you're just like AirPods changed
my life. I'm just listening to audio
books now all the time. So, in terms of
media diet, what do you what are you
reading? What are you paying attention
to these days in terms I don't know
podcasts, newsletters, blogs, things
like that. And then any books in
particular?
>> Yeah. Yeah. So, what I read is basically
I mean I would say read basically three
categories of things. So like in terms
of like general media um it's basically
I I sort of um I always describe it as I
have like a almost a perfect barbell
strategy um which is I read X and I read
old books
right so it's basically either like up
to the minute what's happening right now
um or it's like a book that was written
50 years ago that has stood the test of
time and then you know we're presumably
there's something timeless in it. Um,
and and then it's sort of everything in
the middle I'm always like much more
skeptical about. And and it's particular
it's kind of what I already said, which
is I think if you go back and you read
old nobody ever does this. It's actually
really funny. Nobody ever does this.
There's no market for it. But if you go
back and you read old newspapers,
and by the way, you can you can do this.
Just read last week's newspaper, right?
I guess we're taping on Friday. So read
last Friday's newspaper, right? And just
go back and read it and be like, "Oh my
god, like none of this happened." like n
that none of what they predicted played
out the way that they said that it
would. None of this turned out to
actually be that like relevant or
correct. Like they didn't understand
like you know they by the way they had
no view of what was going to happen this
week that they couldn't know and so they
were making predictions and forecasts
and so forth based on like not having
any information but it's like wow like
you know like none of this happened like
I wish I had never read this like oh my
god. Um and then you know it's kind of
the same thing with magazines like go
back and read old magazines. Um and just
like the the the the level of the you
know the just the endless numbers of
predictions that they make. Yeah. And
and kind of you know the problem with
you know newspapers at least they're
going dayto-day. The thing with
magazines is like every it's like a week
or month you know kind of long cycle and
so it's even you know by the time an
article even hits publication it's you
know it's often out out of date. So I
just I just have like a big problem with
kind of everything in the middle. Um and
so it's either it's either it's either
of the moment or timeless. But then yeah
you mentioned like newsletters. I mean,
so the the other thing and you know,
this is maybe obvious, but I think it's
probably still underrated, which is the
actual practitioners in the field who
are actually creating content, I think
probably is still like dramatically
under underrated and I think this is a
huge part of like the Substack
phenomenon and the newsletter phenomenon
and the podcast phenomenon is like
direct exposure to the people who are
actually principles in the field who
actually know what they're talking about
is probably still dramatically
underrated. And I think again the reason
for that is like we we're we're used to
being in this mass media kind of culture
in which basically everything is
mediated, right? everything got filtered
through like TV interviews or like
newspaper interviews or magazine
interviews and and you know obviously
now more and more it's just no you
actually want like smart people who are
actually working on something explaining
themselves and then you have you know
you have new kinds of intermediation
like podcasts that that that kind of
open that up for people to make that
possible um and so yeah like domain
practitioners are um you know really
great I mean just to state the obvious
and AI you know it's obviously your your
stuff but also like you know let Lex you
know you know the fact that like Lex
Friedman can have you know the world's
leading or you know whoever the you know
any of you guys, you know, there's a
small handful of you guys who have
access to these people. You can have the
world's, you know, kind of leading
experts in the domain actually show up
and and by the way, it's, you know, it
looks the critique always is, you know,
people talk their book, like if I'm
running a startup or whatever, I'm just
selling, but it's like and there's
always a little bit of that. Um, but
it's also, you know, my experience is
people love to talk about what they do
and and you know, they they
fundamentally like want to express what
they do and and and they want to explain
it and they want people to understand it
and everybody kind of enjoys that and
they get to contribute to kind of human
knowledge by doing that and they get ego
gratification by doing that. Um, and so
I think there's just actually just
tremendous amounts of alpha in listening
to the world's leading experts in the
space who actually just like show up and
talk about what they're doing. And of
course like the world is a wash in that
today in a way that it wasn't as
recently as 10 years ago. So I yeah I do
as much of that as I can too.
>> And there's also just this culture in
tech Silicon Valley in particular of
sharing of not trying to keep these
secrets. Everyone on LinkedIn is always
like how is this free like it's just the
way it works.
>> Yeah. It's somebody said Silicon Valley
is a company town but the the the
company is Silicon Valley
>> right and but and again at the level
this goes again there's one of these
great n equals one at the level of n
equals one is somebody you know and I've
run startups before run companies
before. um at the level of n equals one
of like running a company that's just a
giant pain in the butt like
because you know your secrets are
walking out the door and your employees
are walking out the door and the whole
thing sucks. But you know the other side
of it is you also benefit from that
right because you get to hire people
with all these skills and experiences
right and you you're in this you're in
this ecosystem that that adapts right
and channels talents and and and skill
and knowledge and people into into the
new fields and so you know so that you
know there's kind of the push and pull
of that at the level of just being an
individual individual CEO um at the
level of of just being in the ecosystem
to your point like yeah it's it's an
absolutely magical phenomenon and by the
way like you know one of the one of the
you know for all the for all the issues
in Silicon Valley um you know I think AI
I did the comment once I AI is the ninth
major technology platform in the history
of Silicon Valley, right? That, you
know, Silicon Valley is Silicon Valley
is still called Silicon Valley. We
haven't made Silicon here in decades,
right? Uh we used to actually, you know,
it's called Silicon Valley because they
used to make chips, right? They used to
have the like the actual fabs were in
Silicon Valley and then they and they
designed them and they made the chips.
Um and and so and that was you know wave
one starting in the 19 actually that was
like actually no actually more or less
like wave three or whatever but like it
was you know that was when the the
indust the the area was named like in
the 1950s but now we're on like wave
nine right um and and the the company
town phenomenon where the company is the
industry like the the the again the
indeterminate optimism the nobody had
nobody had to sit and plan and say okay
in the 1990s Silicon Valley is going to
do the internet in the 2000s they're
going to do the smartphone in the 2010s
they're going to do the cloud in the
2020s they're going to do AI It it just
the the the the right the indeterminant
optimist optimism of ecosystem
flexibility of the ecosystem met that
the the the Silicon Valley could could
morph um into all these categories and
and again maybe a testimony to
indeterminate optimism.
>> This reminds me of the meme of how we're
all just rappers over sand. Everything
we're building is just rapper wrapper
rapper rapper.
>> The rapper thing is hysterical. Yeah.
Yeah. I'm a I'm a software company now.
I'm I'm a chip rapper, right? Um uh
Yeah. I'm a I'm a I'm a I'm a business
application. I'm a database rapper.
>> Um Yeah, exactly. I'm a sand Yeah. You
and I are you, we're all now sand
rappers.
>> Sand rappers.
>> Perfect.
>> Okay, one more question. Along the media
diet, I asked your partner Ben Harowitz
uh what to talk to you about? Uh the Z
and A16Z if people don't know him. And
he said that you're really into movies
these days.
>> Yeah.
>> And so I don't know any movies. Any
movies you're really into these days?
Any movies you've absolutely loved
recently?
>> Yeah. So the movie that blew my socks
off uh last year, which I think is the
best movie of the decade for sure and
maybe of the last like 15 years, is this
movie. Unfortunately, it's one of these
things. Not a lot of people have seen
it, but I would highly encourage it.
It's called Edington.
>> Not heard of it.
>> Have you not heard of it? Okay. So, Ed,
you're going to really enjoy it. So, I
won't I won't spoil too much of it. So,
at at at at the surface level, this the
following spoils nothing. At the surface
level, it's set in a small town in New
Mexico called Edington, which is a small
town of about 600 people. Um, and um
there's a sheriff uh who's played by
Waqen Phoenix, who's like an old crusty
basically right-winger. And then there's
a um uh there's a mayor uh played by
Pedro Pascal who's basically a young hip
progressive. And uh and then the movie
starts I think in March of 2020. And so
it starts when COVID first hits and then
it sort of as it plays out over the next
few months it it then it intersects and
it it sort of extends into the summer of
2020. So you know kind of the the George
Floyd moment and then the you know the
the protests and riots and kind of
everything. So sort of the convergence
of COVID and then the um and then the uh
and then and then the uh the all the all
the BLM stuff and and and and then um it
and then and then there's a third kind
of element to it which is um there's a
company which is basically a loosely
disguised version of meta if you read
the backstory of it which is building an
AI data center on the outskirts of town.
So they kind of pull that in uh as sort
of a thing that looms larger and larger
over time. And then um the thing it
really is great at is it really shows um
you know this is a small town in New
Mexico and so everybody in the town gets
kind of fully wrapped up in all the co
stuff and they get fully wrapped up in
all the BLM stuff and they get fully
wrapped up in all the like you know tech
anxiety stuff but they're all
experiencing it basically through the
internet right which which is which is
you know what what actually happened
right and so so it it's it's so so the
reason I love the movie so much is one
one is it's the first movie that
directly grapples with 2020 of what
happened in 2020 and it just like fully
fully engages and grapples with like all
the dynamics that were playing out in
the country. But the other reason is
it's the first movie that does a really
good job of showing what it what it what
it was like especially in that era to
live in a world in which there were
things happen in the real world and
people were kind of experiencing events
online, you know, like in a way that was
like very central in their lives, right?
Um and so it does like a really good job
of pulling in like smartphones and
social media um in a way that um uh in a
way that movies really really really
struggle with. And then the whole thing
comes together in an incredibly
entertaining way. Um, and so, and I
won't even say I I I won't even say I
completely agree with the movie or
whatever, and I think the director of
the movie and I would probably disagree
about a lot, but he really tries hard to
like really grapple with like what is
actually like to live like a human being
in the 2020s in America in a way that I
think many other filmmakers who are very
talented have just been very scared of
touching. And and this guy, for some
reason, he's just like, "Yeah, I'm just
going to find all the third rails and
I'm just gonna like grab them."
>> I can see why that's your favorite movie
of the year.
>> It's great. It's great. It's great.
Everybody should see it.
>> Oh, man.
Okay, final question I want to ask about
your piet uh your product diet. Are
there any products you use that maybe
are less known that you love that you
want to recommend? You can, you know,
mention products you're investors in if
if you use them constantly.
>> I mean, we have, you know, we have so
many that it's really hard to, you know,
I always feel it's like, you know, who's
your favorite children? So, it's it's
really hard to to to uh to uh you know,
to to to pull out specific ones. Um, but
I'll, you know, I'll talk about a few.
Um, I mean, just I'll just observations.
So, one is my my 10-year-old. Um I my
10-year-old my 10-year-old right now is
100% obsessed with Replet. Um and and by
the way, it was not from me. Do you have
kids?
>> I do. I have one two and a half year
old.
>> Two and a half. Okay. So, you haven't
run into what I'm running into now,
which is whatever it is you do is not
cool,
right? Like two and a half. Whatever
daddy does is like the coolest thing in
the world. I can tell you by the
time he's 10, whatever you do is like
deeply uncool, right? And and I'm highly
aware of that. Um, and so like if I
mention, oh yeah, we work on XYZ, you
know, he's like, okay. Um, but when he
discovers something, then then it's
cool. Or when his friends tell him about
it, it's cool. And so he he he through
no inter interference on my part uh
discovered Replet about uh about three
months ago and discovered vibe coding
and is like completely obsessed with
vibe coding games and all kinds of all
kinds of things and like literally was s
do it for hours and so I'm seeing that
phenomena play out. Uh which is super
fun. Um uh that's one. Two is I am just
completely in love with all the AI voice
stuff. Um I think it's just absolutely
amazing, hysterical. Uh my favorite
party trick at dinner parties now is to
pull out uh Grock uh with Bad Rudy,
which is if you've seen it's it's the
it's a foul mouse raccoon uh avatar on
the uh in in the Gro app. So um I think
that's super fun. We have this company
Sesame that had, you know, they they
went viral last year for this, uh, you
know, the this just incredibly like, you
know, intimate, emotional, you know,
kind of voice experiences. Um, so I
think the voice stuff is fantastic. I'm
also super fascinated by all the voice
input stuff. Um, and so um, you know,
you know, most recently that company
recently sold, but um, you know, the all
the I think like the pendants, the
wearables, like all that stuff is going
to be big. The meta glasses um, I you
know, I think there's going to be a
whole wearables revolution here. Um, I I
love the voice input stuff. Um, I have
this app on my there's this app on my
phone now called Whisper Flow. Um, which
is voice transcription. Um, which works
like staggeringly well. Um, uh, it's
like incredibly it's like a voice
transcription function, but you can
actually talk to the AM model while
you're doing voice transcription. So,
you can kind of it kind of understands
when you're telling it, no, no, you
know, I want bullet points over there
and I want this and that. And it
understands that you're not telling it
to type in the words I want bullet
points. It just actually understands
that you want bullet points. And so like
that's a great example of a super useful
thing. And so I I think the voice mode
stuff is going to be is going to be uh
is going to be really great.
>> Uh subscribers of my newsletter get a
year free of Replet and Whisper Flow. So
there we go. Uh uh what's the what's the
most memorable thing your son built with
Replet?
>> Oh well so he's gotten super into Star
Trek. Um and so so far it's been he's
like writing like Star Trek simulators.
Um
>> so like all the you know all the by next
generation they actually had
>> Next generation. Okay. I was going to
ask which
>> Well, he like we actually we like them
all. We watched the new Starfleet
Academy last night which actually is
quite is actually quite good. Um but uh
we we watched the original, you know, we
watched we watched them all, but it was
in next generation where they actually
developed an actual design language for
the computers
>> because if if you watch the original
series, they just had like basically,
you know, knobs with lights and they
didn't really, you know, they just like
were like, you know, around on
set trying to pretend they were doing
it. But by next generation, they
actually had designed, they actually had
a UI design language. So, one of the one
of the fun things you can do v coding is
you can say give me a Star Trek next
generation, you know, user interface
for, you know, whatever this that or
whatever. And it actually uses the they
call it this I'm a nerd now. They call
it LCARS um design language and um it'll
you know it'll actually build you like
Star Trek Next Generation British
 um using that design language
but you know with your choice of like a
Star Trek game for example. Um and so
he's he's going crazy for that kind of
thing.
>> That sounds extremely delightful. You
guys should uh open source or release
that. Mark, I like I said, I could talk
to you for hours. Uh, you got things to
do. Uh, anything you want to leave
listeners with before we wrap up?
Anything you want to double down on or
just leave listeners with?
>> Yeah, so a couple things. So, one is we
got super lucky last week. Uh, Py
McCormack uh wrote the best piece ever
written about us actually? Um, which he
released um and so it's the best
explanation of what we do uh and how we
think. And so I I would definitely
recommend that. Um, and then you know
we're putting a lot we have a you know
great team of folks now. We're putting a
lot of effort ourselves into video um in
you know in content um and so I
definitely recommend our YouTube channel
which I I think has a lot of great stuff
and is going to be very exciting in the
next year.
>> Awesome. We'll link to that. I think
it's just YouTube.com6Z
something like that. And you guys have
great stuff.
>> Mark, thank you so much for being here.
>> Awesome. Thank you for having me. I
really I really appreciate it.
>> Bye everyone.
>> Thank you so much for listening. If you
found this valuable, you can subscribe
to the show on Apple Podcasts, Spotify,
or your favorite podcast app. Also,
please consider giving us a rating or
leaving a review as that really helps
other listeners find the podcast. You
can find all past episodes or learn more
about the show at lennispodcast.com.
See you in the next episode.
