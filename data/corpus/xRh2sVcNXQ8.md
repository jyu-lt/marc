# Marc Andreessen on the AI Revolution, Trillion-Dollar Questions, and Why This Is the Biggest Tech Shift of His Lifetime

_An LP AMA covering AI markets, China competition, policy battles, and a16z's multi-strategy approach_

---

## The Magnitude of AI: Bigger Than the Internet

**Marc Andreessen:** This is the biggest technological revolution of my life. Hopefully I'll see more like this in the next 30 years, but this is the big one. In terms of order of magnitude, this is clearly bigger than the internet. The comps on this are things like the microprocessor, the steam engine, electricity—the wheel.

The reason this is so big traces back to the 1930s. There's a great book called _Rise of the Machines_ that goes through this. Back then, there was actually a debate among the people who invented the computer—they understood the theory of computation before they built the things. The debate was whether the computer should be built in the image of "adding machines" or "calculating machines"—essentially cash registers. IBM is actually the successor company to the National Cash Register Company of America.

That was the path the industry took: building these hyper-literal mathematical machines that could execute billions of operations per second, but had no ability to deal with human beings the way humans like to be dealt with. They couldn't understand human speech or language. That's the computer industry built over the last 80 years—mainframes through smartphones.

But they knew at the time—they knew in the '30s—they understood the basic structure of the human brain. They had a theory of human cognition and neural networks. The first neural network academic paper was published in 1943, over 80 years ago. There's an interview you can watch on YouTube with one of the authors, McCulloch, from around 1946—he's in his beach house, not wearing a shirt for some reason, talking about this future where computers would be built on the model of a human brain through neural networks.

That was the path not taken. The neural network as an idea continued to be explored in academia by a rump movement originally called "cybernetics" that became known as artificial intelligence—for basically 80 years. And essentially, it didn't work. Decade after decade of excessive optimism followed by disappointment.

When I was in college in the '80s, there had been a famous AI boom-bust cycle in venture and Silicon Valley. By the time I got to college in '89, in computer science departments, AI was a backwater field—everybody assumed it was never going to happen. But the scientists kept working on it, building up an enormous reservoir of concepts and ideas.

Then we all saw what happened with the ChatGPT moment. All of a sudden it crystallized—"Oh my god, it turns out it works." That was less than three years ago—Christmas of 2022. So we're three years into what is effectively an 80-year revolution actually delivering on all the promise that the people on the alternate path saw from the very beginning.

---

## Why I'm Surprised Every Day

The great news with this technology is it's already ultra-democratized. The best AI in the world is available—launch ChatGPT or Grok or Gemini. You can see how they work. Same thing for video with Sora and VO, for music with Suno and Udio.

Silicon Valley is responding with this incredible rush of enthusiasm. The magic of Silicon Valley is its ability to recycle talent from previous waves of technology into new waves—and inspire an entire new generation. Silicon Valley has this recurring pattern of reallocating capital, building enthusiasm, building critical mass, building funding support and human capital for each new wave.

I'm surprised essentially on a daily basis by what I'm seeing. We track the underlying science and research work very carefully—every day I see a new AI research paper that completely floors me. Some new capability or discovery I would have never anticipated.

On the other side, we see the flow of new products and startups. My jaw is routinely on the floor. It feels like we've unlocked a giant vista.

It will come in fits and starts—this industry routinely gets out over its skis and overpromises. There will be points where things aren't working as well as people thought, or turn out to be too expensive. But the capabilities are truly magical. That's the experience consumers are having. That's the experience businesses are having.

This new wave of AI companies is growing revenue—actual customer revenue, actual demand translated to dollars showing up in bank accounts—at an absolutely unprecedented takeoff rate. We're seeing companies grow much faster than anything I've ever seen before. It feels like we're just at the very beginning.

---

## The Economics: Consumer and Enterprise Business Models

There are basically two core business models: consumer and enterprise/infrastructure.

### Consumer AI

We live in a very interesting world where the internet exists and is fully deployed. Sometimes people ask, "Is AI like the internet revolution?" A little bit, but with the internet, we had to build it—enormous amounts of fiber in the ground, mobile cell towers, shipments of smartphones and tablets. The internet was invented in the 1960s-70s. Consumer internet was new in the early '90s. We didn't get broadband to the home until the 2000s. We didn't get mobile broadband until around 2010. The original iPhone in 2007 didn't have broadband—it was on a narrowband 2G network.

But the internet got built. Now you have 5 billion people on some version of mobile broadband. Smartphones sell for as little as $10. Projects like Jio in India are bringing the remaining population online.

Consumer AI products can deploy to all those people as quickly as they want to adopt. The internet is the carrier wave for AI to proliferate at light speed into the global population. This is a rate of proliferation far faster than ever possible before. You couldn't download electricity. You couldn't download indoor plumbing. You can download AI.

The AI consumer killer applications are growing at an incredible rate—and monetizing really well. Including at higher price points. The AI companies are more creative on pricing than the SaaS companies were. It's now becoming routine to have $200 or $300 per month tiers for consumer AI, which I think is very positive. A lot of companies cap their opportunity by capping their pricing too low.

### Enterprise AI

The question is: what is intelligence worth? If you can inject more intelligence into your business—raise customer service scores, increase upsells, reduce churn, run marketing campaigns more effectively—these are direct business payoffs people are seeing already. If you can infuse AI into new products—your car talks to you, everything in the world starts to get really smart—what's that worth?

The leading AI infrastructure companies are growing revenues incredibly quickly. The pull is tremendous.

The core business model is basically "tokens by the drink"—tokens of intelligence per dollar. And the price of AI is falling much faster than Moore's law. All the inputs into AI on a per-unit basis—the costs are collapsing. This hyper-deflation of per-unit cost is driving more than corresponding demand growth with elasticity.

Tokens by the drink are going to get a lot cheaper from here. That's going to drive enormous demand. Everything in the cost structure is going to get optimized.

---

## Big Models vs. Small Models

A lot of data center build is oriented around training and serving the big models. But the small model revolution is happening at the same time.

If you track the capability of leading-edge models over time, after 6 or 12 months there's a small model that's just as capable. The capabilities of the big models are being shrunk down at smaller size and smaller cost quite quickly.

The most recent example: there's a Chinese company that produces the model called Kimi. The new version is a reasoning model that, according to benchmarks, basically replicates the reasoning capabilities of GPT-5—which cost a tremendous amount to develop and serve. And all of a sudden, you can run it on one or two MacBooks. If you're a business wanting GPT-5-capable reasoning but don't want to pay those costs or want to run it locally, you can do that.

What will OpenAI do? Obviously they're going to GPT-6. There's this laddering where the entire industry moves forward—big models getting more capable, small models chasing them and providing completely different deployment options at very low price points.

Some very smart people think everything will only run in big models because they're always the smartest—why would you ever want something less intelligent? The counterargument: there's a huge number of tasks that don't require Einstein. A 120 IQ person is great; you don't need a 160 IQ PhD in string theory for someone who's competent and capable.

I tend to think the AI industry will be structured like the computer industry: a small handful of "supercomputers"—we call them god models—running in giant data centers. Then a cascade of smaller models all the way down to very small models running on embedded systems, on individual chips inside every physical item in the world. The smartest models will always be at the top, but the volume will be the smaller models that proliferate out. That's what happened with microchips, with operating systems, with a lot of everything else we built in software.

---

## The Chip Dynamics

If you look at the entire history of the chip industry, shortages become gluts. Anytime there's a giant profit pool in a new chip category, somebody has a lead for a while and gets the profits appropriate to what we call robust market share—but in time that draws competition.

Nvidia is an absolutely fantastic company, fully deserving of their position and profits. But they're now so valuable, generating so many profits, that it's the bat signal of all time to the rest of the chip industry. AMD is coming at them. The hyperscalers are building their own chips. The Chinese are building their own chips.

It's pretty likely in 5 years that AI chips will be cheap and plentiful compared to today—extremely positive for the economics of the companies we invest in.

On the startup side: it's a little bit of historical happenstance that AI is running on GPUs—graphical processing units. GPUs were the second chip in every PC for graphics, 3D gaming, CAD/CAM, Photoshop. Nvidia fought the GPU wars for 30 years and came out the winner—but it was a hyper-competitive market that was actually not that high margin or that big.

Then it turned out that two other forms of computation were incredibly valuable and happened to be massively parallel—good fits for the GPU architecture: cryptocurrency starting about 15 years ago, and AI starting about 4 years ago.

If you were designing AI chips from scratch today, you wouldn't build a full GPU. You'd build dedicated AI chips much more specifically adapted and economically efficient. There are startups building entirely new kinds of chips oriented specifically for AI. It's hard to build a chip company from scratch, but some are doing well. They might make it on their own or get bought by big companies that can scale them.

The Koreans, the Japanese, and the Chinese are all going to play here too. There will be many choices of AI chips in the future—a giant battle we'll observe carefully and ensure our companies take full advantage of.

---

## The China Question: A Two-Horse Race

You want to start these discussions by acknowledging the debate: How much are we in a new cold war with China? It's tempting to see it like US vs. USSR in the 20th century. The counter-argument: it's more complicated because the US and USSR were never intertwined from a trade standpoint. The USSR never really made anything anybody needed—their primary exports were wheat and oil.

China exports a tremendous number of physical things, including a huge part of the supply chain for everything American manufacturers make. By the time an American company brings a toy, car, computer, or smartphone to market, it's got a lot of componentry made in China. There's a much tighter interlinkage than between American and Soviet economies.

Adam Smith might say that's good news for peace—both countries need each other. The Chinese governance model is based on high employment. If China had 25-50% unemployment, it would cause civil unrest—the one thing the CCP doesn't want. China needs the American export market. The American consumer is a third of global consumer demand. Without the US export market, a lot of Chinese factories would go instantly bankrupt.

That said, the mood in DC for the last 10 years on a bipartisan basis has been that we need to take China more seriously as a geopolitical foe. There's the military dimension—risk of war in the South China Sea, around Taiwan. There's the economic question around de-industrialization and potential re-industrialization.

And there's the AI question—which is economic but also geopolitical. AI is essentially only being built in the US and China. The rest of the world either can't build it or doesn't want to. AI is going to proliferate all over the world—will it be American AI or Chinese AI?

The Chinese are in the game for sure. DeepSeek was the starting gun in the software race. You've got DeepSeek (from a hedge fund, which surprised everyone), Qwen (Alibaba), Kimi (Moonshot), and then Tencent, Baidu, ByteDance—somewhere between three and six primary AI companies plus tremendous numbers of startups.

They're in the race on software. They're working incredibly hard to catch up on chips. The common understanding is that the new version of DeepSeek hasn't dropped yet because the Chinese government instructed them to build it only on Chinese chips—to motivate the Chinese chip ecosystem. Huawei is the main chip company there.

And then there's everything to follow—AI in robotic form. There's a global technological-economic robotics competition kicking off. China starts ahead on robotics because they're ahead on so many components—the entire supply chain of electromechanical things moved from the US to China 30 years ago.

### The DeepSeek Supernova

The DeepSeek release was surprising on multiple fronts:

1. **How good it was**: It took capabilities running in large cloud models and shrunk them to run on small amounts of local hardware.

2. **Open source from China**: China doesn't have a long history of open source.

3. **From a hedge fund**: Not a big university research lab or tech company. An incredibly successful quant hedge fund with super geniuses, whose founder decided to build AI. Even the Chinese government seemed surprised.

This is encouraging—it means maybe you don't need superstar researchers. Smart kids can just build this stuff, which is the direction things are headed.

The cynics in DC say they're dumping—trying to commoditize it out of the gate. There's probably something to that. But it's also just: wow, they're really in the race.

The policy fights of the last two years changed as a result. Two years ago, there was a push to restrict or ban a lot of AI. That's easy when you're the only game in town. Quite another thing if you're in a foot race with China. The policy landscape in DC has improved dramatically with awareness that this is a two-horse race, not a one-horse race.

---

## Policy and Regulation: Navigating 1,200 State Bills

Two years ago I was very worried about ruinous federal legislation on AI. We engaged heavily. The good news: the risk of that sitting here today is very low. There's very little mood in DC on either side of the aisle to do anything that would prevent us from beating China.

That's translated a lot of attention to the states. Under federalism, states get to pass their own laws. Right now we're tracking on the order of **1,200 bills across the 50 states**—not just blue states, also red states. Republicans are not a monolith on this. There are quite a few local Republican officials with misinformed or ill-advised views trying to put out bad bills.

It's strange this is happening. Technology and AI are obviously national in scope—interstate commerce. The federal government should be the regulator, not the states. But the federal government needs to assert itself.

There was an attempt to add a moratorium on state-level AI regulation to the "one big beautiful bill"—reserve the right of the federal government to regulate AI and prevent states from moving forward. That deal blew up at the last minute. The moratorium was probably too much of a stretch in restricting certain state regulations they should be able to do.

We're having very active discussions in DC. The administration is supportive of the federal government being in charge. Most Congress people on both sides get this.

### The California SB1047 Disaster

California inexplicably decided to copycat the EU AI Act. The EU AI Act basically killed AI development in Europe. Even Apple and Meta aren't launching leading-edge AI capabilities in Europe—that's how draconian it was.

The EU has this view: if we can't be leaders in innovation, at least we can be leaders in regulation. Classic European self-harm. Now they're trying to unwind it, along with GDPR. Mario Draghi's report on European competitiveness outlined all the ways Europe was holding itself back, including overregulation of AI.

SB1047 would have completely killed AI development in California. Our governor vetoed it at the last minute after it passed both houses. One of the worst provisions: it would have assigned **downstream liability to open source developers** for any misuse of their code.

You're an independent developer or academic. You develop and release an AI model. It works fine. Five years later it gets built into a nuclear power plant, there's a meltdown, and somebody says it's the AI's fault. The legal liability would be assigned back to you—the open source developer.

Completely insane. It would completely kill open source, kill startups doing open source, completely kill academic research in its entirety. That's the level of playing with fire these state politicians have become enamored with.

The feds understand this. I suspect it will get resolved. It just needs to happen because it doesn't make sense to let states operate suicidally.

We call this our "little tech agenda." We're extremely focused on freedom for startups to innovate. We operate in a completely bipartisan fashion with extensive support on both sides. It's truly bipartisan, very policy-based, aligned with the country's interests.

Why us? Tragedy of the commons—every venture firm and tech company should weigh in, but most don't. Ben and I concluded the stakes were too high. If we're going to be the industry leader, we have to take responsibility for our own destiny. That's the cost of being the leader.

---

## The Trillion-Dollar Questions

These are trillion-dollar questions, not answers. Depending on how they're answered, they'll drive trillions of dollars of market value.

### Will Open Source or Closed Source Win?

I think this is still very open. The closed-source models keep getting better. If you take the temperature of people working at the big labs on proprietary models, they'll tell you progress is continuing at a very rapid pace.

There's periodic concern online that capabilities are topping out. But the people at the big labs say: "Oh no, we have 800 new ideas. We have tons of ways to make these things better. We're making new discoveries all the time." The big models are going to continue to get better quickly.

And the open-source models continue to get better. Every month there's another big release like this Kimi thing—amazing how they shrunk that capability to a very small form factor.

The nice benefit of open source is it's easy to learn from. If you're a CS professor teaching AI, a student learning, an engineer at a normal company, or somebody in their basement with a startup idea—the existence of state-of-the-art open source models is amazing education. They show you how to do everything.

The proliferation of knowledge about how to build AI is expanding very fast—compared to a counterfactual where it was all bottled up in two or three big companies. That knowledge is generating a lot of new people.

AI researchers today are getting paid more than professional athletes—a supply-demand imbalance, not enough to go around. But shortages create gluts. Smart people are coming up to speed very quickly. Some of the best AI people in the world are 22, 23, 24. They can't have been experts their whole lives—they came up to speed in the last four or five years. There will be a lot more in the future.

The long-term answer may well be both. If you believe my pyramid industry structure, there'll certainly be a large business of whatever is the smartest thing regardless of cost. But there will also be a giant volume market of smaller models everywhere.

### Will Incumbents or Startups Win?

Big companies are definitely playing hard—Google, Meta, Amazon, Microsoft. Then there are the new incumbents like Anthropic and OpenAI.

But even in the last two years, you've had this birth of brand-new companies that are almost instant incumbents. XAI is one. Mistral is the great outlier to my Europe point—doing very well as the French/European AI champion, the exception that proves the rule.

We've funded foundation model startups: Ilya out of OpenAI, Mira Murati also out of OpenAI, Fei-Fei Li out of Stanford for a world foundation model company. There are new swings, all early but very promising.

And there's a giant explosion of AI application companies—startups that take the technology and field it in specific domains: law, medicine, education, creativity.

### Are Application Companies Just "GPT Wrappers"?

The critique is that application companies aren't doing anything that preserves value—they're surfacing AI from somebody else. Pass-through shell things that ultimately won't have value.

It actually turns out the opposite is happening. The leading AI application companies like Cursor are discovering they don't just use a single model. As products get more sophisticated, they use many different models custom-tailored to specific aspects. They may start using one model but end up using a dozen, then 50 or 100 for different aspects.

And they build a lot of their own models—backward integrating because they have the deepest understanding of their domain. They can also pick up open-source models if they don't like the economics of buying intelligence by the drink.

The best AI application companies are full-fledged deep technology companies actually building their own AI.

### What About Pricing: Usage-Based or Value-Based?

It's actually fairly amazing what's happened. These big tech companies with incredible R&D capabilities are building big AI models with incredible new intelligence. They were already in the cloud war—AWS vs. Azure vs. Google Cloud.

In an alternate universe, they could have kept their magic AI secret and captive. Instead, they've proliferated their magic new technology through their cloud business—incredible scale, hyper competition between providers, prices coming down fast.

The most magic new technology in the world is basically being served up as a cloud business, made available to everybody on the planet to click and use for relatively small amounts of money, on a usage basis. Usage is great for startups—there's basically no fixed cost for a startup building an AI app. They can just tap into OpenAI or Anthropic or Google tokens by the drink and get going.

From the startup standpoint, it's marvelous—the most magical thing in the world available by the drink.

But that doesn't mean the optimal pricing model for all applications should be tokens by the drink. We have dedicated pricing experts and spend a lot of time with companies on this. A core principle: you don't want to price by cost if you can avoid it. You want to price by value—a percentage of the business value you're delivering.

Some AI startups are pricing by the drink. Many others are exploring: if AI can do the job of a coder, doctor, nurse, radiologist, lawyer, paralegal, or teacher—can you price by value and get a percentage of what would have literally been a person? Or price by marginal productivity—if you make a human doctor much more productive with AI, can you price as a percentage of the productivity uplift?

**High prices are underappreciated.** The naive view is lower price = better for customer. The sophisticated view: higher prices are often good for the customer because the vendor can invest more in R&D and make the product better faster. Companies with higher margins can make better products. The high price can be a gift for the customer—making the vendor better, the product better, and ultimately the customer better off.

I'm encouraged by the degree to which AI entrepreneurs are willing to run these experiments.

---

## A16Z's Multi-Strategy Approach

When a company is confronted with fundamentally open strategic or economic questions, it's often a big problem. Companies need a specific strategy—very specific concrete choices about investment dollars and personnel. The strategy has to be logical and coherent or the company collapses into chaos. If they get the answers wrong, they're in real trouble.

Venture has issues, but a huge advantage: **we don't have to bet on just one strategy.** We can bet on multiple strategies at the same time.

We are aggressively investing behind every strategy we've identified that has a plausible chance of working—even when that's contradictory to another strategy we're investing in. The world's messy. A lot of things are going to work. There won't be clean yes or no answers—a lot will be "and" answers.

If one strategy doesn't work, we're not trying to hedge per se, but we'll have representation of the alternate strategy. Multiple ways to win.

That's why I have a big smile on my face when I say there are big open questions. I think that actually works to our advantage.

---

## Two Years Since the AI Reorganization: What We Got Right

The whole theory of venture is that money is made when there's a fundamental architecture shift—a fundamental change in the technology landscape. That's been true forever. With fundamental change, you have this period of creativity where aggressive people can start new companies and win categories before big companies can respond. Without fundamental change, it's very hard to make startups work because big companies just do everything.

The best venture capital firms in history are the ones most aggressive at navigating from wave to wave.

When I came to Silicon Valley in 1994, there was no "internet venture capital firm." But there were firms like Kleiner Perkins that said, "This is a new architecture. It seems crazy. Everybody says you can't make money. But we're going to make those bets." KP in the '90s invested in us, Amazon, Google, @Home. They'd started in the 1970s around minicomputers—three generations of technology back—and navigated from wave to wave. Same for Sequoia, for any successful firm in business 30-50 years.

It was pretty amazing that most of the venture ecosystem decided to sit crypto out. Between the Bitcoin white paper in 2009 and the crypto war beginning in 2021, the number of VCs who said "we're not going to do crypto"—I never quite know what to do with a VC who deliberately doesn't participate in a new wave of technology. Is that not the job?

AI is another one where certain firms are jumping all over it and others are sitting back. There were firms very well known and successful in the '80s that didn't make the jump to the internet and basically petered out.

We got the magnitude right—this is a fundamental transformation. AD is doing great and also a beneficiary of AI: a lot of AD products benefit from AI, and AI is a driver of demand in sectors like energy and materials. Crypto is back to being exciting due to policy changes. There will be intersections between AI and crypto. Biotech and healthcare are obviously being transformed by AI—drug discovery, healthcare delivery.

The individual efforts feel good. The interactions between teams and hybrid ideas—companies coming at things from multiple angles—feel really good.

What are we missing? Right now, not a vertical. There's not a specific area where we need a new unit or fund. It's more about executing extremely well in the verticals we have and being the best possible partner to portfolio companies.

---

## On Ben, Disagreement, and Public Footprint

**Question:** What do you and Ben disagree and commit on?

We're an old married couple—the romance is long dead. We're in the park squabbling all the time. We debate everything, argue about everything. But what's made our partnership work is we tend to come to the same conclusion—each of us is open to being persuaded.

There are zero issues where I'm thinking "I can't believe I'm putting up with this crazy thing on his part that I really disagree with but have to commit to." And I don't think vice versa.

The biggest thing we discuss—not the most important thing we're doing, but since someone asked—is the public footprint of the company. Our presence in the world in terms of public statements, controversy, how we vocalize our views.

There's a real tension. Generally speaking, the more outspoken and controversial we are, the better for the business—entrepreneurs love it. Founders want to work with people who are brave and controversial, articulate things clearly. It's a demonstration of courage. And it teaches them who we are before they even meet us.

This is why we started with a very active marketing strategy from the beginning—and it completely worked. If we broadcast our message clearly, even controversially, the best founders understand us before walking in the door. As opposed to everyone else in venture keeping everything quiet, where founders have no idea who these people are.

On the other hand, there are externalities to being publicly visible and controversial on many fronts. We're trying to thread this needle—not backing off of outbound, tripling down on being leaders articulating tech and business issues. A fair amount of our communications are aimed at Washington—if you're a policymaker 3,000 miles away and your only information source is East Coast newspapers that hate Silicon Valley, that's bad.

We meet people in DC all the time who say, "Most of what I know about this topic I learned from you guys—I listened to the podcast, read the articles, watched the YouTube channel."

But Ben and I do go back and forth on exactly how many third-rail topics we should touch and how frequently. We are trying to moderate that.

---

## Society, Adoption, and Revealed Preferences

For a very long time, tech wasn't very relevant. But go back 300-500 years and there are recurring waves of total panic caused by new technology. The printing press was hand-in-hand with Protestantism. There have been multiple automation panics for 200 years. A lot of the foundational panic under Marxism was fear of job elimination through automation.

In the 1960s there was panic around AI replacing jobs—the "Committee for the Triple Revolution" sent a manifesto to the Johnson White House about stopping the march of technology.

In the last 20 years: panic around outsourcing in the 2000s, panic around robots in the 2010s (even though robots didn't work), and now AI panic.

We in Silicon Valley have always wanted our work to matter. Most of our time, people tell us everything we're doing is stupid and won't work. Then that flips into panic about how it's going to ruin everything. It's easy to be cynical, but we need to be very respectful. We're the dog that caught the bus. People really do care about these things—it's our responsibility to think carefully and explain ourselves.

### The Gap Between What People Say and What They Do

If you want to understand people, there are two ways: ask them or watch them. Every social scientist knows: the answers you get when you ask are very different than when you watch—revealed preferences.

People have opinions on all kinds of things and express themselves in heated ways. But if you watch their behavior, they're often calmer, more measured, more rational.

**If you run a survey of what American voters think about AI, they're in total panic.** "This is terrible, it's going to kill all the jobs, ruin everything."

**If you watch revealed preferences, they're all using AI.** They're downloading apps, using ChatGPT at work. They're having an argument with their partner, cutting and pasting the text exchange into ChatGPT to have it explain what their partner is thinking and how to respond. They have a skin condition and finally learning about their own health by taking a photo. They had to get a report ready and ran out of time—ChatGPT saved their bacon.

People in their daily lives are not only using this technology, they love it. They're adopting as fast as they possibly can.

The public discussion will ping-pong back and forth because of this divergence. But what people are doing is the part that ultimately wins. This technology is going to be exactly the same as every other one: proliferate really broadly, freak everybody out, and 20 years from now—or 5 years, or 1 year—everybody's going to be like, "Thank god we've got this. Wouldn't life be miserable without it?"

I'm very optimistic about where this lands. There will be turbulence along the way.

---

## Lightning Round

**What is something you've changed your mind on recently?**

It's like every day. It's almost all about what's in the realm of the possible. I'm terrible at specific examples. It's often somebody showing up—something someone writes or says. Very frequently somebody very young.

**Do you plan to be cryogenically frozen?**

Not with current cryogenic technology. The track record is not great. The stories are somewhat horrifying.

**How do you stay grounded when your influence itself may distort reality around you?**

The concern is real. The reality-warping effect is definitely real—and there's a very big advantage to it: being able to get people to do what you want. But it is a concern for having an accurate understanding.

One: my partners, including Ben, are quite forthright in telling me when I'm wrong.

Two: we're very exposed to reality. We run experiments—we make decisions about whether to invest. Reality kicks in quickly. The delusions don't last very long in this business. These things either work or they don't. You have long elaborate discussions about theories, then reality smacks you in the face—"you idiot, what were you thinking?"

The ultimate frustration of the business, which is also very motivating: the number of times you think you've applied superior analysis, invested or not invested based on that, and it turns out the analysis was completely wrong. You completely overrated your ability to epistemically analyze things.

And I do have the entire internet ready to tell me I'm an idiot. That doesn't hurt. It does on a regular basis.

**Do you plan to go to Mars?**

Probably not. I'm not even willing to leave California. I'm barely willing to leave my house. Maybe by VR.

Having said that, I think Elon's going to pull it off. I wouldn't be surprised if within a decade there are routine trips back and forth. This may actually become a practical question. I do know a lot of people who are probably going to go.

---

_AMA conducted with a16z LPs_
